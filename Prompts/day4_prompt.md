# 第4天开发任务 Prompt

## 📅 第4天：多轮对话引导功能

### 任务目标
完善多轮对话引导功能，优化选择题生成逻辑，使用LLM生成更自然的问题文本，完善对话流程控制，提升用户体验。

---

## 核心要求（严格审查）

根据开发项目描述.md，必须严格遵循以下要求：

### **多轮对话引导**
- 当检索结果较多时（>5个），通过提问帮助用户缩小范围
- **提问方式**：优先使用**选择题**形式，而非开放式问题
- 基于当前检索结果动态生成选项
- 最终返回的文档列表不超过 5 个
- 如果超过 5 个结果，继续提问缩小范围

### **示例对话**
```
用户：我要一个东风天龙的仪表图
Chatbot：我找到了东风天龙相关的电路图。请问您需要的是：
A. 东风天龙 KL 系列
B. 东风天龙 KC 系列
C. 东风天龙 VL 系列

用户：A
Chatbot：明白了。请问您需要的是哪种类型的仪表电路图：
A. ECU 仪表针脚图
B. 整车仪表线路图

用户：整车仪表线路图
Chatbot：已为您找到以下电路图：
[ID: 12345] 东风天龙KL整车仪表电路图
```

---

## 上午任务（4小时）

### 1. 选择题生成逻辑优化

#### 当前状态
- ✅ 已有基础的问题生成服务（QuestionService）
- ✅ 已有选项提取功能（extract_options）
- ⚠️ 需要优化：使用LLM生成更自然的问题文本

#### 任务清单

##### 1.1 选项提取算法优化
- [ ] 优化 `extract_options` 方法
  - 当结果>5个时，分析层级路径
  - 提取可用的筛选维度（品牌、型号、类型等）
  - 实现选项去重和排序
  - 限制选项数量（3-5个）
- [ ] 优化选项排序策略
  - 按结果数量降序排列
  - 优先显示更常见的选项
  - 避免选项过于相似

##### 1.2 LLM生成问题文本
- [ ] 在 `QuestionService` 中集成LLM服务
- [ ] 实现 `generate_question_text_with_llm()` 方法
  - 输入：选项类型、选项列表、当前结果数量、对话上下文
  - 输出：自然流畅的问题文本
- [ ] 设计问题生成Prompt模板
  - 参考示例对话风格
  - 生成简洁明确的问题
  - 包含上下文信息（如"我找到了XX相关的电路图"）

##### 1.3 问题文本生成策略
- [ ] 设计问题生成规则
  - 优先按层级顺序提问（品牌 -> 型号 -> 类型）
  - 根据当前结果动态生成问题
  - 避免重复提问已筛选的类型
- [ ] 格式化选择题输出（A/B/C/D格式）
- [ ] 优化问题表述，使其更自然

#### 实现位置
- `backend/app/services/question_service.py`（扩展）
- `backend/app/services/llm_service.py`（扩展，添加问题生成方法）

---

### 2. 问题生成策略优化

#### 任务清单

##### 2.1 动态问题生成
- [ ] 实现智能问题类型选择
  - 分析当前结果，选择最有效的筛选维度
  - 优先选择能最大程度缩小范围的维度
  - 避免选择结果数量相近的维度
- [ ] 实现问题优先级算法
  - 品牌优先级：高（通常能快速缩小范围）
  - 型号优先级：中高（在品牌确定后）
  - 类型优先级：中（在品牌和型号确定后）
  - 类别优先级：低（最后使用）

##### 2.2 上下文感知
- [ ] 在问题生成时考虑对话历史
  - 避免重复提问
  - 根据已筛选的条件调整问题
  - 提供更精准的选项

##### 2.3 选项质量优化
- [ ] 实现选项去重
  - 合并相似选项（如"东风天龙"和"东风天龙KL"）
  - 避免选项过于细分
- [ ] 实现选项排序
  - 按结果数量降序
  - 优先显示常见选项

#### 实现位置
- `backend/app/services/question_service.py`（扩展）
- `backend/app/services/search_service.py`（扩展extract_options方法）

---

## 下午任务（4小时）

### 3. 对话流程控制完善

#### 任务清单

##### 3.1 对话状态机优化
- [ ] 完善对话状态转换逻辑
  - 初始搜索 -> 选择题 -> 继续筛选 -> 返回结果
  - 处理状态转换异常
  - 确保状态一致性
- [ ] 实现结果收敛逻辑
  - 当结果≤5个时返回
  - 当无法进一步筛选时返回
  - 当所有维度都已筛选时返回

##### 3.2 用户选择处理优化
- [ ] 优化用户选择解析
  - 支持A/B/C/D/E选项字母
  - 支持选项名称（完全匹配或部分匹配）
  - 支持用户直接输入选项名称
- [ ] 处理无效选择
  - 友好的错误提示
  - 重新显示选项
  - 允许用户重新选择

##### 3.3 边界情况处理
- [ ] 处理无结果情况
  - 当筛选后无结果时，提示用户
  - 建议用户返回上一步或重新搜索
- [ ] 处理用户重新表达需求
  - 检测用户是否重新表达需求（如"我要找XXX"）
  - 重置对话状态，重新开始搜索
- [ ] 处理用户返回上一步（可选）
  - 支持"返回"、"上一步"等指令
  - 恢复上一次的筛选状态

##### 3.4 多轮筛选优化
- [ ] 避免重复提问
  - 记录已筛选的类型
  - 跳过已筛选的维度
- [ ] 优化筛选顺序
  - 根据结果动态调整筛选顺序
  - 优先筛选能最大程度缩小范围的维度

#### 实现位置
- `backend/app/api/chat.py`（完善对话流程）
- `backend/app/models/conversation.py`（扩展状态管理）

---

### 4. 交互优化

#### 任务清单

##### 4.1 友好的错误提示
- [ ] 实现友好的错误消息
  - 当无法识别用户选择时
  - 当搜索无结果时
  - 当筛选后无结果时
- [ ] 使用LLM生成友好的提示文本（可选）
- [ ] 提供建议和帮助信息

##### 4.2 问题表述优化
- [ ] 优化问题文本，使其更自然
  - 使用LLM生成自然的问题
  - 参考示例对话风格
  - 包含上下文信息
- [ ] 优化选项展示
  - 清晰的选项格式
  - 显示每个选项的结果数量
  - 便于用户选择

##### 4.3 对话体验优化
- [ ] 优化消息格式
  - 清晰的结果展示
  - 友好的对话语气
  - 适当的提示信息
- [ ] 优化响应速度
  - 缓存常见问题
  - 优化LLM调用（减少token数量）
  - 异步处理（可选）

#### 实现位置
- `backend/app/api/chat.py`（优化响应格式）
- `backend/app/services/question_service.py`（优化问题生成）

---

## 代码结构设计

### 需要修改的文件
```
backend/app/
├── services/
│   ├── question_service.py      # 扩展：LLM生成问题文本
│   └── llm_service.py          # 扩展：添加问题生成方法
├── api/
│   └── chat.py                  # 完善：对话流程控制
└── models/
    └── conversation.py          # 扩展：状态管理
```

### QuestionService扩展接口

```python
class QuestionService:
    """问题生成服务（扩展）"""
    
    def generate_question_with_llm(
        self,
        results: List[ScoredResult],
        option_type: str,
        options: List[Dict],
        context: Dict = None
    ) -> Dict:
        """使用LLM生成自然的问题文本"""
        pass
    
    def generate_question_text_with_llm(
        self,
        option_type: str,
        options: List[Dict],
        total_count: int,
        context: Dict = None
    ) -> str:
        """使用LLM生成问题文本"""
        pass
    
    def optimize_options(
        self,
        options: List[Dict],
        max_options: int = 5
    ) -> List[Dict]:
        """优化选项列表（去重、排序）"""
        pass
```

### LLMService扩展接口

```python
class LLMService:
    """LLM服务（扩展）"""
    
    def generate_question_text(
        self,
        option_type: str,
        options: List[Dict],
        total_count: int,
        context: Dict = None
    ) -> str:
        """生成问题文本"""
        pass
```

---

## Prompt模板设计

### 问题生成Prompt模板

```
你是一个智能车辆电路图资料导航助手。请根据以下信息生成一个自然、简洁的选择题问题：

**当前情况**：
- 找到了 {total_count} 个相关结果
- 需要用户选择{option_type_name}来缩小范围

**可选选项**：
{options_list}

**对话上下文**：
{context_info}

请生成一个问题，要求：
1. 问题简洁明确，不超过30字
2. 语气友好自然，参考以下示例风格：
   - "我找到了东风天龙相关的电路图。请问您需要的是："
   - "明白了。请问您需要的是哪种类型的仪表电路图："
3. 不要包含选项列表（选项会单独显示）
4. 如果上下文中有已筛选的信息，可以在问题中提及

只返回问题文本，不要包含其他内容。
```

---

## 交付物检查清单

### 必须完成
- [ ] 选择题生成逻辑优化完成
- [ ] 使用LLM生成自然的问题文本
- [ ] 选项提取和排序优化
- [ ] 对话流程控制完善
- [ ] 用户选择处理优化
- [ ] 边界情况处理完善
- [ ] 友好的错误提示实现
- [ ] 问题表述优化完成

### 代码质量要求
- 代码结构清晰，职责分离
- 注释完整，函数有文档字符串
- 错误处理完善
- 遵循Python最佳实践
- 符合开发项目描述.md中的要求

---

## 开发注意事项

1. **严格遵循要求**：必须使用选择题形式，而非开放式问题
2. **问题文本自然**：使用LLM生成自然的问题文本，参考示例对话风格
3. **选项质量**：确保选项清晰、去重、排序合理
4. **对话流程**：确保多轮对话流程顺畅，避免重复提问
5. **错误处理**：完善边界情况处理，提供友好的错误提示
6. **性能优化**：注意LLM调用成本，考虑缓存和优化

---

## 测试建议

### 测试用例
1. **多轮对话测试**：
   - "我要一个东风天龙的仪表图"
   - 验证选择题生成
   - 验证多轮筛选流程
   - 验证最终结果≤5个

2. **选项生成测试**：
   - 验证选项去重
   - 验证选项排序
   - 验证选项数量限制（3-5个）

3. **问题文本测试**：
   - 验证问题文本自然流畅
   - 验证问题包含上下文信息
   - 验证问题符合示例风格

4. **边界情况测试**：
   - 无结果情况
   - 筛选后无结果
   - 用户输入无效选择
   - 用户重新表达需求

5. **对话流程测试**：
   - 验证状态转换正确
   - 验证避免重复提问
   - 验证结果收敛逻辑

---

## 下一步准备

完成第4天后，为第5天做准备：
- 确保多轮对话功能完整可用
- 为前端界面优化做准备
- 确保API接口稳定可靠

---

**开始开发！** 🚀



