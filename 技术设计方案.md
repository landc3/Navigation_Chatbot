# 智能车辆电路图资料导航 Chatbot - 技术设计方案

## 一、LLM选择分析

### 1.1 需求分析

本项目对LLM的使用场景：
- **意图理解**：解析用户自然语言，提取品牌、型号、类型等信息（短文本，<100字）
- **选择题生成**：基于检索结果生成自然的问题和选项（中等文本，<500字）
- **对话管理**：理解用户选择（A/B/C/D或文本），管理对话状态

**关键点**：
- 不需要处理超长文本（4235条数据不算大）
- 主要需要**中文理解能力**和**结构化输出**
- 需要**快速响应**（用户体验）
- 需要考虑**成本**（API调用费用）

### 1.2 LLM对比分析

| LLM | 优势 | 劣势 | 适用场景 | 推荐度 |
|-----|------|------|---------|--------|
| **Kimi (Moonshot)** | ✅ 长文本能力强（200K上下文）<br>✅ 中文理解好<br>✅ 价格相对便宜 | ❌ 对于本项目来说能力过剩<br>❌ 响应速度可能较慢 | 需要处理超长文档的场景 | ⭐⭐⭐ |
| **GPT-3.5-turbo** | ✅ 响应速度快<br>✅ API稳定<br>✅ 中文支持好 | ❌ 需要科学上网（国内）<br>❌ 成本较高 | 快速开发，追求稳定性 | ⭐⭐⭐⭐ |
| **GPT-4** | ✅ 理解能力最强<br>✅ 结构化输出好 | ❌ 成本高<br>❌ 响应慢 | 对准确性要求极高 | ⭐⭐⭐ |
| **通义千问** | ✅ 国内可用<br>✅ 中文理解好<br>✅ 价格便宜 | ❌ API文档可能不够完善 | 国内项目首选 | ⭐⭐⭐⭐⭐ |
| **文心一言** | ✅ 国内可用<br>✅ 百度生态 | ❌ 性能一般 | 备选方案 | ⭐⭐⭐ |
| **Claude (Anthropic)** | ✅ 对话能力强<br>✅ 安全性好 | ❌ 国内访问困难 | 海外项目 | ⭐⭐⭐ |

### 1.3 推荐方案

**首选：通义千问（Qwen）**
- ✅ 国内可用，无需翻墙
- ✅ 中文理解能力强
- ✅ 价格便宜（约0.008元/1K tokens）
- ✅ 适合本项目的中文场景

**备选：Kimi (Moonshot)**
- ✅ 如果通义千问API有问题，Kimi是很好的备选
- ✅ 虽然长文本能力用不上，但中文理解也很好
- ✅ 价格合理

**不推荐：GPT-4**
- ❌ 成本太高（约0.03元/1K tokens）
- ❌ 对于本项目来说性能过剩

### 1.4 LLM使用策略

**分层使用策略**：
1. **意图理解**：使用轻量级模型（如通义千问 Qwen-Plus）
2. **选择题生成**：使用标准模型（如通义千问 Qwen-Max）
3. **备用方案**：如果主LLM失败，自动切换到Kimi

**Prompt设计原则**：
- 使用结构化输出（JSON格式）
- 明确角色和任务
- 提供示例（Few-shot learning）
- 限制输出长度

---

## 二、数据预处理方案

### 2.1 数据结构分析

**原始数据**：
```
ID,层级路径,关联文件名称
1,电路图->ECU电路图->工程机械->三一->德国仪表,三一挖掘机_德国仪表显示器针脚定义
```

**层级路径特点**：
- 深度不固定（3-6层）
- 层级含义不统一（有些是品牌，有些是型号）
- 分隔符：`->`

**文件名称特点**：
- 包含品牌、型号、类型信息
- 使用下划线`_`分隔
- 可能包含特殊标记（如【国六】、【直喷】）

### 2.2 预处理步骤

#### 步骤1：数据加载与清洗
```python
# 伪代码
def load_data(csv_path):
    df = pd.read_csv(csv_path)
    
    # 清洗数据
    df['层级路径'] = df['层级路径'].str.strip()
    df['关联文件名称'] = df['关联文件名称'].str.strip()
    
    # 解析层级路径
    df['层级列表'] = df['层级路径'].str.split('->')
    df['层级深度'] = df['层级列表'].apply(len)
    
    return df
```

#### 步骤2：建立索引结构

**2.2.1 倒排索引（关键词 -> 文档ID）**
```python
# 为每个文档建立关键词索引
index = {
    '三一': [1, 2, 3, ...],      # 品牌索引
    '东风': [100, 101, ...],     # 品牌索引
    '仪表': [1, 2, 16, ...],     # 类型索引
    '天龙': [200, 201, ...],     # 型号索引
    ...
}
```

**2.2.2 层级索引（层级路径 -> 文档ID）**
```python
# 按层级建立索引
hierarchy_index = {
    '电路图': {
        'ECU电路图': {
            '工程机械': {
                '三一': [1, 2, 3, ...],
                '徐工': [8, 9, 10, ...],
            },
            '商用车': {
                '东风': [100, 101, ...],
            }
        },
        '整车电路图': {...}
    }
}
```

**2.2.3 全文索引（文件名称分词）**
```python
# 使用jieba分词，建立全文索引
import jieba

def build_fulltext_index(df):
    index = {}
    for idx, row in df.iterrows():
        # 分词
        words = jieba.cut(row['关联文件名称'])
        for word in words:
            if len(word) > 1:  # 过滤单字
                if word not in index:
                    index[word] = []
                index[word].append(row['ID'])
    return index
```

#### 步骤3：建立同义词映射

```python
# 同义词词典
synonyms = {
    '仪表图': ['仪表', '仪表电路图', '仪表针脚图', '仪表显示器'],
    'ECU': ['ECU电路图', '电脑板', 'ECM'],
    '天龙': ['东风天龙'],
    'KL': ['天龙KL', 'KL系列'],
    'JH6': ['解放JH6', 'JH6系列'],
    'C81': ['福田C81'],
    '4HK1': ['五十铃4HK1', '4HK1发动机'],
    ...
}
```

#### 步骤4：品牌/型号/类型提取

```python
# 从层级路径和文件名称中提取结构化信息
def extract_metadata(row):
    levels = row['层级列表']
    filename = row['关联文件名称']
    
    # 提取品牌（通常在层级路径的第3-4层）
    brand = None
    for level in levels:
        if level in ['三一', '徐工', '东风', '解放', '重汽', ...]:
            brand = level
            break
    
    # 提取型号（通常在文件名称中）
    model = extract_model_from_filename(filename)
    
    # 提取类型（ECU电路图/整车电路图）
    diagram_type = levels[1] if len(levels) > 1 else None
    
    return {
        'brand': brand,
        'model': model,
        'type': diagram_type,
        'category': levels[2] if len(levels) > 2 else None,
    }
```

### 2.3 预处理后的数据结构

```python
# 预处理后的文档对象
{
    'id': 1,
    'hierarchy_path': '电路图->ECU电路图->工程机械->三一->德国仪表',
    'hierarchy_levels': ['电路图', 'ECU电路图', '工程机械', '三一', '德国仪表'],
    'filename': '三一挖掘机_德国仪表显示器针脚定义',
    'metadata': {
        'brand': '三一',
        'model': None,
        'type': 'ECU电路图',
        'category': '工程机械',
    },
    'keywords': ['三一', '挖掘机', '德国仪表', '显示器', '针脚定义'],
    'fulltext': '三一挖掘机_德国仪表显示器针脚定义',  # 用于全文搜索
}
```

---

## 三、匹配规则设计

### 3.1 匹配策略（多级匹配）

采用**多级匹配策略**，从精确到模糊：

```
Level 1: 精确匹配（完全匹配）
  ↓ 如果结果<5个，返回结果
Level 2: 关键词匹配（部分匹配）
  ↓ 如果结果<5个，返回结果
Level 3: 模糊匹配（同义词、拼音）
  ↓ 如果结果<5个，返回结果
Level 4: 语义匹配（LLM理解）
  ↓ 如果结果<5个，返回结果
Level 5: 无结果，提示用户
```

### 3.2 匹配算法详细设计

#### 3.2.1 意图提取（使用LLM）

```python
def extract_intent(user_query):
    """
    使用LLM提取用户意图
    返回结构化信息
    """
    prompt = f"""
    请从以下用户查询中提取信息，返回JSON格式：
    {{
        "brand": "品牌（如：三一、东风、解放等）",
        "model": "型号（如：天龙KL、JH6等）",
        "type": "电路图类型（如：仪表图、ECU电路图、整车电路图等）",
        "keywords": ["关键词列表"]
    }}
    
    用户查询：{user_query}
    """
    
    response = llm_call(prompt)
    return json.loads(response)
```

#### 3.2.2 多维度匹配

```python
def search_circuit_diagrams(intent, df, indexes):
    """
    多维度匹配算法
    """
    results = []
    scores = {}  # {doc_id: score}
    
    # 1. 品牌匹配（权重：0.3）
    if intent['brand']:
        brand_docs = indexes['brand'].get(intent['brand'], [])
        for doc_id in brand_docs:
            scores[doc_id] = scores.get(doc_id, 0) + 0.3
    
    # 2. 型号匹配（权重：0.4）
    if intent['model']:
        # 在文件名称中搜索
        model_matches = df[df['关联文件名称'].str.contains(intent['model'], na=False)]
        for _, row in model_matches.iterrows():
            scores[row['ID']] = scores.get(row['ID'], 0) + 0.4
    
    # 3. 类型匹配（权重：0.2）
    if intent['type']:
        type_docs = indexes['type'].get(intent['type'], [])
        for doc_id in type_docs:
            scores[doc_id] = scores.get(doc_id, 0) + 0.2
    
    # 4. 关键词匹配（权重：0.1）
    for keyword in intent['keywords']:
        keyword_docs = indexes['keyword'].get(keyword, [])
        for doc_id in keyword_docs:
            scores[doc_id] = scores.get(doc_id, 0) + 0.1
    
    # 5. 文件名称全文匹配（权重：0.3）
    query_text = ' '.join(intent['keywords'])
    for _, row in df.iterrows():
        filename = row['关联文件名称']
        # 计算相似度（使用简单的字符串包含）
        if query_text in filename or any(kw in filename for kw in intent['keywords']):
            scores[row['ID']] = scores.get(row['ID'], 0) + 0.3
    
    # 6. 层级路径匹配（权重：0.2）
    hierarchy_text = '->'.join(intent.get('hierarchy', []))
    for _, row in df.iterrows():
        if hierarchy_text in row['层级路径']:
            scores[row['ID']] = scores.get(row['ID'], 0) + 0.2
    
    # 排序并返回Top N
    sorted_results = sorted(scores.items(), key=lambda x: x[1], reverse=True)
    return [doc_id for doc_id, score in sorted_results[:20]]  # 返回Top 20用于后续筛选
```

#### 3.2.3 相关性评分算法

```python
def calculate_relevance_score(doc, intent, query):
    """
    计算文档相关性分数
    """
    score = 0.0
    
    # 1. 品牌完全匹配（+1.0）
    if doc['metadata']['brand'] == intent['brand']:
        score += 1.0
    
    # 2. 型号完全匹配（+1.0）
    if intent['model'] and intent['model'] in doc['filename']:
        score += 1.0
    
    # 3. 类型匹配（+0.8）
    if doc['metadata']['type'] == intent['type']:
        score += 0.8
    
    # 4. 文件名称包含查询关键词（+0.5 per keyword）
    for keyword in intent['keywords']:
        if keyword in doc['filename']:
            score += 0.5
    
    # 5. 层级路径匹配（+0.3）
    for level in doc['hierarchy_levels']:
        if level in query:
            score += 0.3
    
    # 6. 同义词匹配（+0.2）
    for synonym_group in synonyms.values():
        if any(word in query for word in synonym_group):
            if any(word in doc['filename'] for word in synonym_group):
                score += 0.2
                break
    
    return score
```

### 3.3 匹配规则优先级

**优先级排序**（从高到低）：
1. **完全匹配**：品牌+型号+类型完全匹配
2. **品牌+型号匹配**：品牌和型号都匹配
3. **品牌+类型匹配**：品牌和类型匹配
4. **型号+类型匹配**：型号和类型匹配
5. **单一维度匹配**：只有品牌/型号/类型之一匹配
6. **关键词匹配**：文件名称包含关键词
7. **模糊匹配**：同义词或部分匹配

### 3.4 特殊处理规则

#### 3.4.1 模糊表达处理

```python
# 模糊表达映射
fuzzy_mapping = {
    '天龙': '东风天龙',
    'KL': '天龙KL',
    'JH6': '解放JH6',
    'C81': '福田C81',
    '豪瀚': '重汽豪瀚',
    '豪汉': '重汽豪汉',
    '杰狮': '红岩杰狮',
    '乘龙': '东风乘龙',
    '欧曼': '福田欧曼',
}

def expand_fuzzy_query(query):
    """扩展模糊查询"""
    for fuzzy, expanded in fuzzy_mapping.items():
        query = query.replace(fuzzy, expanded)
    return query
```

#### 3.4.2 同义词处理

```python
def expand_synonyms(keywords):
    """扩展同义词"""
    expanded = set(keywords)
    for keyword in keywords:
        for synonym_group in synonyms.values():
            if keyword in synonym_group:
                expanded.update(synonym_group)
    return list(expanded)
```

#### 3.4.3 拼音匹配（可选）

```python
from pypinyin import lazy_pinyin

def pinyin_match(query, text):
    """拼音匹配"""
    query_pinyin = ''.join(lazy_pinyin(query))
    text_pinyin = ''.join(lazy_pinyin(text))
    return query_pinyin in text_pinyin
```

---

## 四、选择题生成策略

### 4.1 选项提取算法

当检索结果>5个时，需要生成选择题：

```python
def generate_choices(search_results, df):
    """
    从搜索结果中提取选项
    """
    # 1. 分析结果中的层级分布
    level_stats = {}
    for doc_id in search_results:
        doc = df[df['ID'] == doc_id].iloc[0]
        levels = doc['层级列表']
        
        # 统计每个层级的选项
        for i, level in enumerate(levels):
            if i not in level_stats:
                level_stats[i] = {}
            level_stats[i][level] = level_stats[i].get(level, 0) + 1
    
    # 2. 选择最有区分度的层级
    # 选择选项数量在3-5个之间的层级
    best_level = None
    for level_idx, stats in level_stats.items():
        unique_options = len(stats)
        if 3 <= unique_options <= 5:
            best_level = level_idx
            break
    
    # 3. 提取选项
    if best_level is not None:
        options = list(level_stats[best_level].keys())
        return {
            'level': best_level,
            'options': options,
            'question': generate_question(best_level, options)
        }
    
    # 4. 如果没有合适的层级，使用品牌或型号
    return generate_brand_or_model_choices(search_results, df)
```

### 4.2 问题生成

```python
def generate_question(level_idx, options):
    """
    使用LLM生成自然的问题
    """
    level_names = {
        0: '电路图类型',
        1: '电路图类型',
        2: '车辆类别',
        3: '品牌',
        4: '型号',
        5: '其他属性'
    }
    
    level_name = level_names.get(level_idx, '选项')
    
    prompt = f"""
    请根据以下选项生成一个自然的中文问题（选择题格式）：
    层级：{level_name}
    选项：{', '.join(options)}
    
    要求：
    1. 问题简洁明了
    2. 使用A/B/C/D格式
    3. 语气友好自然
    
    示例：
    选项：['东风天龙 KL', '东风天龙 KC', '东风天龙 VL']
    问题：我找到了东风天龙相关的电路图。请问您需要的是：
    A. 东风天龙 KL 系列
    B. 东风天龙 KC 系列
    C. 东风天龙 VL 系列
    """
    
    return llm_call(prompt)
```

---

## 五、技术架构设计

### 5.1 系统架构图

```
┌─────────────┐
│   前端      │
│  (React)    │
└──────┬──────┘
       │ HTTP
       ↓
┌─────────────┐
│   后端API   │
│  (FastAPI)  │
└──────┬──────┘
       │
       ├──→ 意图理解模块 (LLM)
       ├──→ 检索模块 (索引+匹配算法)
       ├──→ 选择题生成模块 (LLM)
       └──→ 对话管理模块 (状态机)
```

### 5.2 数据流

```
用户输入
  ↓
意图提取 (LLM)
  ↓
多级匹配 (索引+算法)
  ↓
结果>5个？
  ├─ 是 → 生成选择题 (LLM) → 用户选择 → 继续筛选
  └─ 否 → 返回结果
```

---

## 六、性能优化建议

### 6.1 索引优化
- 使用**内存索引**（4235条数据可以全部加载到内存）
- 使用**字典/哈希表**实现O(1)查找
- 预处理时建立所有索引，避免实时计算

### 6.2 缓存策略
- **LLM结果缓存**：相同查询缓存结果
- **搜索结果缓存**：相同意图缓存搜索结果
- **选择题缓存**：相同选项组合缓存问题文本

### 6.3 并发处理
- 使用**异步IO**（FastAPI支持）
- LLM调用使用**异步请求**
- 数据库查询使用**连接池**

---

## 七、总结

### 7.1 关键技术选型
- **LLM**：通义千问（主）+ Kimi（备）
- **检索**：多级匹配 + 相关性评分
- **数据预处理**：倒排索引 + 层级索引 + 全文索引
- **匹配规则**：精确匹配 → 关键词匹配 → 模糊匹配 → 语义匹配

### 7.2 核心优势
1. **多级匹配**：从精确到模糊，确保召回率
2. **智能引导**：通过选择题快速缩小范围
3. **中文优化**：针对中文场景优化（同义词、拼音）
4. **性能优化**：索引+缓存，快速响应

### 7.3 开发优先级
1. **第1优先级**：基础检索功能（关键词匹配）
2. **第2优先级**：LLM意图理解
3. **第3优先级**：选择题生成
4. **第4优先级**：性能优化和界面美化

---

**设计完成！可以开始开发了！** 🚀


