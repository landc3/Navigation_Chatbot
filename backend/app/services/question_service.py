"""
é—®é¢˜ç”ŸæˆæœåŠ¡æ¨¡å—
æ ¹æ®æœç´¢ç»“æœç”Ÿæˆé€‰æ‹©é¢˜ï¼Œå¼•å¯¼ç”¨æˆ·ç¼©å°èŒƒå›´
"""
from typing import List, Dict, Optional, Any
import re
import string
from backend.app.models.circuit_diagram import CircuitDiagram
from backend.app.models.types import ScoredResult, rebuild_scored_result_model
from backend.app.services.search_service import get_search_service
from backend.app.services.llm_service import get_llm_service
from backend.app.utils.category_pattern_loader import get_pattern_loader
from backend.app.utils.option_merge_util import merge_similar_options

# ç¡®ä¿ ScoredResult æ¨¡å‹å·²é‡å»ºï¼ˆè§£å†³å‰å‘å¼•ç”¨é—®é¢˜ï¼‰
rebuild_scored_result_model()


class QuestionService:
    """é—®é¢˜ç”ŸæˆæœåŠ¡"""
    
    def __init__(self):
        """åˆå§‹åŒ–é—®é¢˜ç”ŸæˆæœåŠ¡"""
        self.search_service = get_search_service()
        self.llm_service = get_llm_service()
        self.pattern_loader = get_pattern_loader()  # åŠ è½½åˆ†ç±»æ¨¡å¼é…ç½®

    @staticmethod
    def _make_option_labels(n: int) -> List[str]:
        """
        ç”Ÿæˆè¶³å¤Ÿæ•°é‡çš„é€‰é¡¹æ ‡ç­¾ï¼šA..Z, AA..AZ, BA..BZ...
        """
        if n <= 0:
            return []
        letters = string.ascii_uppercase

        def idx_to_label(idx: int) -> str:
            # Excel-style column naming (0-based)
            out = ""
            x = idx
            while True:
                x, rem = divmod(x, 26)
                out = letters[rem] + out
                if x == 0:
                    break
                x -= 1
            return out

        return [idx_to_label(i) for i in range(n)]
    
    def generate_question(
        self,
        results: List[ScoredResult],
        min_options: int = 2,
        max_options: int = 5,
        excluded_types: Optional[List[str]] = None,
        context: Optional[Dict[str, Any]] = None,
        use_llm: bool = True
    ) -> Optional[Dict]:
        """
        æ ¹æ®æœç´¢ç»“æœç”Ÿæˆé€‰æ‹©é¢˜
        
        Args:
            results: æœç´¢ç»“æœåˆ—è¡¨
            min_options: æœ€å°‘é€‰é¡¹æ•°
            max_options: æœ€å¤šé€‰é¡¹æ•°
            excluded_types: è¦æ’é™¤çš„é€‰é¡¹ç±»å‹åˆ—è¡¨ï¼ˆå¦‚ï¼š["brand", "model"]ï¼‰ï¼Œç”¨äºè·³è¿‡å·²ç»é€‰æ‹©çš„ç±»å‹
            context: å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰ï¼ŒåŒ…å«filter_historyç­‰ä¿¡æ¯
            use_llm: æ˜¯å¦ä½¿ç”¨LLMç”Ÿæˆé—®é¢˜æ–‡æœ¬ï¼ˆé»˜è®¤Trueï¼‰
            
        Returns:
            é—®é¢˜å­—å…¸ï¼ŒåŒ…å«é—®é¢˜æ–‡æœ¬å’Œé€‰é¡¹åˆ—è¡¨ï¼Œå¦‚æœæ— æ³•ç”Ÿæˆåˆ™è¿”å›None
            æ ¼å¼: {
                "question": "é—®é¢˜æ–‡æœ¬",
                "options": [
                    {"label": "A", "name": "é€‰é¡¹å", "count": æ•°é‡, "type": "brand"},
                    ...
                ],
                "option_type": "brand"  # é€‰é¡¹ç±»å‹
            }
        """
        if not results or len(results) < min_options:
            return None
        
        # ä¼˜å…ˆå°è¯•æ–‡æ¡£ä¸»é¢˜åˆ†ç±»ï¼ˆå½“ç»“æœæ•°é‡è¾ƒå¤šä¸”æŸ¥è¯¢æ›´åƒâ€œä¸»é¢˜è¯â€è€Œä¸æ˜¯â€œè½¦å‹ç³»åˆ—/ECUä»£å·â€æ—¶ï¼‰
        # ä¾‹å¦‚ï¼š"VGTæ‰§è¡Œå™¨"ã€"è§£æ”¾åŠ¨åŠ›"ã€"é¾™æ“åŠ¨åŠ›"ã€"æ¶¡è½®å¢å‹å™¨"ç­‰
        #
        # æ³¨æ„ï¼šè‹¥æŸ¥è¯¢å½¢å¦‚â€œå¤©é¾™KLç”µè·¯å›¾â€â€œæ¬§æ›¼ETX...â€æˆ–â€œC81ç”µè·¯å›¾â€è¿™ç±»æ›´åƒâ€œè½¦å‹ç³»åˆ—/ECUä»£å·â€çš„åœºæ™¯ï¼Œ
        # åº”ä¼˜å…ˆèµ° variant åˆ†ç»„ï¼ˆå·²æœ‰å›å½’æµ‹è¯•è¦†ç›–ï¼‰ï¼Œé¿å…è¢« document_category æŠ¢å é¦–è½®é—®é¢˜ç±»å‹ã€‚
        current_query = (context or {}).get("current_query") or ""
        has_ecu_code = bool(re.search(r"[A-Za-z]{1,6}\d{1,3}", current_query))
        looks_like_cn_plus_series = bool(re.search(r"[\u4e00-\u9fff]{1,8}[A-Z]{2,4}", current_query))

        if len(results) >= 6 and not (has_ecu_code or looks_like_cn_plus_series):
            doc_category_options = self._extract_document_category_options(results, max_options=max_options)
            print(f"ğŸ” æ–‡æ¡£ç±»åˆ«æå–ç»“æœ: {len(doc_category_options) if doc_category_options else 0} ä¸ªé€‰é¡¹")
            if doc_category_options and len(doc_category_options) >= min_options:
                # å¦‚æœæå–åˆ°çš„ç±»åˆ«æ•°é‡>=10ï¼Œå°è¯•æ–‡ä»¶åå‰ç¼€åˆå¹¶ï¼ˆåœ¨finalizeä¹‹å‰ï¼‰
                current_option_type = "document_category"
                if len(doc_category_options) >= 10:
                    print(f"âœ… æ£€æµ‹åˆ°ç±»åˆ«æ•°é‡ >= 10 ({len(doc_category_options)})ï¼Œå°è¯•æ–‡ä»¶åå‰ç¼€åˆå¹¶...")
                    merged_options = self._merge_filename_prefixes(results, doc_category_options, max_options=max_options)
                    print(f"ğŸ” åˆå¹¶ç»“æœ: {len(merged_options) if merged_options else 0} ä¸ªé€‰é¡¹")
                    if merged_options and len(merged_options) < len(doc_category_options) and len(merged_options) >= min_options:
                        # ä½¿ç”¨åˆå¹¶åçš„é€‰é¡¹
                        print(f"âœ… åˆå¹¶æˆåŠŸ: {len(doc_category_options)} -> {len(merged_options)}")
                        doc_category_options = merged_options
                        current_option_type = "filename_prefix"
                    else:
                        print(f"âš ï¸ åˆå¹¶å¤±è´¥æˆ–æ— æ•ˆ: merged_options={merged_options is not None}, len={len(merged_options) if merged_options else 0}, min_options={min_options}")
                else:
                    print(f"â„¹ï¸ ç±»åˆ«æ•°é‡ < 10 ({len(doc_category_options)})ï¼Œè·³è¿‡æ–‡ä»¶åå‰ç¼€åˆå¹¶")
                
                # å¦‚æœæˆåŠŸæå–åˆ°æ–‡æ¡£ä¸»é¢˜åˆ†ç±»ï¼Œä¼˜å…ˆä½¿ç”¨
                options = self._finalize_options_with_ids(
                    option_type=current_option_type,
                    options=doc_category_options,
                    results=results,
                    max_options=max_options,
                    context=context,
                )
                if options and len(options) >= min_options:
                    
                    question_text = self._generate_question_text(current_option_type, len(results), context)
                    option_labels = self._make_option_labels(min(max_options, len(options)))
                    formatted_options = []
                    for i, option in enumerate(options[:max_options]):
                        formatted_options.append({
                            "label": option_labels[i],
                            "name": option['name'],
                            "count": int(option.get("count") or 0),
                            "type": current_option_type,
                            "ids": option.get("ids") if isinstance(option, dict) else None,
                        })
                    return {
                        "question": question_text,
                        "options": formatted_options,
                        "option_type": current_option_type
                    }
            # å¦‚æœæ–‡æ¡£ä¸»é¢˜åˆ†ç±»æå–å¤±è´¥æˆ–æå–åˆ°çš„ç±»åˆ«å¤ªå¤šï¼ˆæ¥è¿‘ç»“æœæ•°é‡ï¼‰ï¼Œç›´æ¥å°è¯•æ–‡ä»¶åå‰ç¼€åˆå¹¶
            elif len(results) >= 10:
                # ç›´æ¥åŸºäºæ–‡ä»¶åç”Ÿæˆé€‰é¡¹å¹¶å°è¯•åˆå¹¶
                filename_options = []
                for result in results:
                    file_name = result.diagram.file_name or ""
                    filename_options.append({
                        "name": file_name,
                        "count": 1,
                        "ids": [result.diagram.id]
                    })
                
                # å°è¯•åˆå¹¶æ–‡ä»¶åå‰ç¼€
                merged_options = self._merge_filename_prefixes(results, filename_options, max_options=max_options)
                if merged_options and len(merged_options) >= min_options and len(merged_options) < len(results):
                    options = self._finalize_options_with_ids(
                        option_type="filename_prefix",
                        options=merged_options,
                        results=results,
                        max_options=max_options,
                        context=context,
                    )
                    if options and len(options) >= min_options:
                        question_text = self._generate_question_text("filename_prefix", len(results), context)
                        option_labels = self._make_option_labels(min(max_options, len(options)))
                        formatted_options = []
                        for i, option in enumerate(options[:max_options]):
                            formatted_options.append({
                                "label": option_labels[i],
                                "name": option['name'],
                                "count": int(option.get("count") or 0),
                                "type": "filename_prefix",
                                "ids": option.get("ids") if isinstance(option, dict) else None,
                            })
                        return {
                            "question": question_text,
                            "options": formatted_options,
                            "option_type": "filename_prefix"
                        }
        
        # æŒ‰ä¼˜å…ˆçº§å°è¯•ç”Ÿæˆé—®é¢˜ï¼šè½¦å‹å˜ä½“(variant) -> å“ç‰Œ+å‹å·ç»„åˆ -> å“ç‰Œ -> é…ç½® -> å‹å· -> ç±»å‹ -> ç±»åˆ«
        # å¦‚æœç”¨æˆ·å·²ç»é€‰æ‹©äº†å“ç‰Œï¼Œå°è¯•ä½¿ç”¨å“ç‰Œ+å‹å·ç»„åˆ
        option_types = []
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»é€‰æ‹©äº†å“ç‰Œå’Œç±»å‹
        has_brand_filter = False
        has_type_filter = False
        if excluded_types:
            has_brand_filter = "brand" in excluded_types
            has_type_filter = "type" in excluded_types
        
        # è‹¥ç”¨æˆ·è¾“å…¥å½¢å¦‚â€œå¤©é¾™KLç”µè·¯å›¾â€ï¼Œé¦–è½®ä¼˜å…ˆæŒ‰â€œè½¦å‹å˜ä½“å‰ç¼€â€åˆ†ç»„ï¼ˆæ›´ç¬¦åˆä¸šåŠ¡æœŸæœ›ï¼‰
        current_query = (context or {}).get("current_query") or ""
        has_diagram_kw = ("ç”µè·¯å›¾" in current_query) or ("ç”µè·¯" in current_query and "å›¾" in current_query)
        # series code: KL/KC/VL... ; ecu/code: C81 / EDC17C81 ...
        has_ecu_code = bool(re.search(r"[A-Za-z]{1,6}\d{1,3}", current_query))
        has_series_code = bool(re.search(r"[A-Z]{2,3}", current_query)) and not has_ecu_code

        # å¦‚æœå·²ç»é€‰æ‹©äº†å“ç‰Œå’Œç±»å‹ï¼Œä¼˜å…ˆè¯¢é—®ç³»åˆ—ï¼ˆå“ç‰Œåé¢çš„å±‚çº§ï¼‰ï¼Œå…¶æ¬¡è¯¢é—®é…ç½®/è½´å‹
        force_hierarchy_extraction = False
        if has_brand_filter and has_type_filter:
            # ç”¨æˆ·å·²ç»æŒ‡å®šäº†å“ç‰Œå’Œç±»å‹ï¼Œå¿…é¡»è¯¢é—®ç³»åˆ—ï¼ˆå¦‚KLã€KCç­‰ï¼‰
            # åªå°è¯•brand_modelç±»å‹ï¼Œä¸å…è®¸fallbackåˆ°å…¶ä»–ç±»å‹
            option_types = ["brand_model", "config"]
            # å¼ºåˆ¶ä½¿ç”¨å±‚çº§è·¯å¾„æå–ï¼Œä¸å…è®¸ä½¿ç”¨æ ‡å‡†æ–¹æ³•
            force_hierarchy_extraction = True
        elif has_brand_filter:
            # ç”¨æˆ·å·²ç»é€‰æ‹©äº†å“ç‰Œï¼Œä¼˜å…ˆè¯¢é—®ç³»åˆ—ï¼Œç„¶åæ‰æ˜¯ç±»å‹
            option_types = ["brand_model", "config", "model", "type", "category"]
        else:
            # å¦åˆ™ï¼Œå…ˆå°è¯•å•ä¸€ç»´åº¦ï¼Œå¦‚æœå•ä¸€ç»´åº¦é€‰é¡¹ä¸è¶³ï¼Œå†å°è¯•ç»„åˆç»´åº¦
            # ä¼˜å…ˆå°è¯•å“ç‰Œ+å‹å·ç»„åˆï¼Œå› ä¸ºè¿™æ ·å¯ä»¥ä»å±‚çº§è·¯å¾„ä¸­æå–æ›´ç²¾ç¡®çš„é€‰é¡¹
            option_types = ["brand_model", "brand", "config", "model", "type", "category"]

        # â€œä»£å·/ç³»åˆ—ç  + ç”µè·¯å›¾â€åœºæ™¯ï¼šæŠŠ variant æ”¾åˆ°æœ€å‰é¢ï¼ˆå¹¶é¿å…è¢« excluded_types è¿‡æ»¤ï¼‰
        if has_diagram_kw and (has_series_code or has_ecu_code):
            if not excluded_types or "variant" not in excluded_types:
                option_types = ["variant"] + [t for t in option_types if t != "variant"]
        
        # å¦‚æœæŒ‡å®šäº†è¦æ’é™¤çš„ç±»å‹ï¼Œè·³è¿‡å®ƒä»¬
        if excluded_types:
            option_types = [opt_type for opt_type in option_types if opt_type not in excluded_types]

        # ç±»å‹ç›´è¿”è§„åˆ™ï¼ˆå…³é”®ï¼‰ï¼šå¦‚æœå€™é€‰çš„â€œdiagram_typeâ€åªæœ‰ä¸€ç§ï¼Œå°±ä¸è¦å†é—®ç±»å‹ï¼Œç›´æ¥é—®ä¸‹ä¸€ç»´åº¦
        # è¿™èƒ½é¿å…â€œæ˜æ˜éƒ½åªæœ‰æ•´è½¦ç”µè·¯å›¾ï¼Œå´è¿˜åœ¨é—®ä½ è¦å“ªç§ç±»å‹â€çš„ä½æ•ˆæ¾„æ¸…ã€‚
        if "type" in option_types:
            unique_types = {r.diagram.diagram_type for r in results if getattr(r.diagram, "diagram_type", None)}
            if len(unique_types) <= 1:
                option_types = [t for t in option_types if t != "type"]
        
        # å¦‚æœæ‰€æœ‰ç±»å‹éƒ½è¢«æ’é™¤äº†ï¼Œè¿”å› None
        if not option_types:
            return None
        
        for option_type in option_types:
            # åŒé‡æ£€æŸ¥ï¼šç¡®ä¿å½“å‰ç±»å‹ä¸åœ¨æ’é™¤åˆ—è¡¨ä¸­
            if excluded_types and option_type in excluded_types:
                continue
            
            # ç‰¹æ®Šå¤„ç†ï¼švariant/brand_model/config éœ€è¦ç‰¹æ®Šæå–é€»è¾‘
            if option_type == "variant":
                options = self._extract_variant_options(results, max_options=max_options, context=context)
            elif option_type == "brand_model":
                # ä¼˜å…ˆä»å±‚çº§è·¯å¾„ä¸­æå–å“ç‰Œ+ç³»åˆ—ç»„åˆ
                options = self._extract_options_from_hierarchy(results, max_options, context)
                print(f"ğŸ” _extract_options_from_hierarchyè¿”å›é€‰é¡¹æ•°: {len(options) if options else 0}")
                # å¦‚æœæå–å¤±è´¥ï¼Œä¸”ä¸æ˜¯å¼ºåˆ¶å±‚çº§æå–ï¼Œä½¿ç”¨æ ‡å‡†æ–¹æ³•
                if not options or len(options) < min_options:
                    if not force_hierarchy_extraction:
                        print(f"âš ï¸ å±‚çº§æå–å¤±è´¥ï¼Œå°è¯•æ ‡å‡†æ–¹æ³•")
                        options = self._extract_brand_model_options(results, max_options)
                        print(f"ğŸ” _extract_brand_model_optionsè¿”å›é€‰é¡¹æ•°: {len(options) if options else 0}")
                    else:
                        # å¼ºåˆ¶å±‚çº§æå–æ—¶ï¼Œå¦‚æœå¤±è´¥ï¼Œå°è¯•æ›´æ¿€è¿›çš„æå–ç­–ç•¥
                        print(f"âš ï¸ å¼ºåˆ¶å±‚çº§æå–å¤±è´¥ï¼Œå°è¯•æ›´æ¿€è¿›çš„æå–ç­–ç•¥")
                        # å°è¯•ä»æ‰€æœ‰å±‚çº§è·¯å¾„ä¸­æå–ç³»åˆ—ä»£ç ï¼Œä¸é™åˆ¶ä½ç½®
                        options = self._extract_series_codes_aggressive(results, max_options, context)
                        print(f"ğŸ” æ¿€è¿›æå–è¿”å›é€‰é¡¹æ•°: {len(options) if options else 0}")
                        # å¦‚æœæ¿€è¿›æå–ä¹Ÿå¤±è´¥ï¼Œè‡³å°‘å°è¯•ä»æ–‡ä»¶åä¸­æå–
                        if not options or len(options) < min_options:
                            print(f"âš ï¸ æ¿€è¿›æå–ä¹Ÿå¤±è´¥ï¼Œå°è¯•ä»æ–‡ä»¶åæå–ç³»åˆ—ä»£ç ")
                            options = self._extract_series_from_filenames(results, max_options, context)
                            print(f"ğŸ” æ–‡ä»¶åæå–è¿”å›é€‰é¡¹æ•°: {len(options) if options else 0}")
            elif option_type == "type":
                # å…³é”®ä¿®å¤ï¼š
                # - â€œtypeâ€ å¿…é¡»æŒ‰å½“å‰å€™é€‰é›†çš„ diagram_type è¿›è¡Œ**åˆ†æ¡¶**ï¼ˆæ¯æ¡æ•°æ®åªå±äºä¸€ä¸ªæ¡¶ï¼‰ï¼Œ
                #   å¦åˆ™ä¼šå‡ºç°â€œé€‰é¡¹æ˜¾ç¤º4æ¡ï¼Œä½†ç‚¹è¿›å»å˜33æ¡â€çš„ä¸¥é‡ä¸ä¸€è‡´ã€‚
                options = self._extract_disjoint_type_options(results, max_options=max_options)
            elif option_type == "config":
                options = self._extract_config_variants(results, max_options=max_options, context=context)
            else:
                options = self.search_service.extract_options(
                    results,
                    option_type,
                    max_options=max_options
                )
            
            # å¦‚æœé€‰é¡¹æ•°é‡ä¸è¶³ï¼Œå°è¯•ä»å±‚çº§è·¯å¾„ä¸­æå–é€‰é¡¹
            if not options or len(options) < min_options:
                if option_type == "variant":
                    # variant æ²¡æœ‰æ›´å¥½çš„å›é€€ç­–ç•¥ï¼Œäº¤ç»™åç»­ option_type ç»§ç»­å°è¯•
                    pass
                elif option_type == "brand_model":
                    # å°è¯•ä»å±‚çº§è·¯å¾„ä¸­æå–å“ç‰Œ+å±‚çº§ç»„åˆ
                    options = self._extract_options_from_hierarchy(results, max_options, context)
                elif option_type == "type":
                    # å¯¹äºç±»å‹ï¼Œå°è¯•æå–ç±»å‹å˜ä½“
                    options = self._extract_type_variants(results, max_options, context)
                elif option_type in ["brand", "model", "category"]:
                    # å¯¹äºå…¶ä»–ç±»å‹ï¼Œä¹Ÿå°è¯•ä»å±‚çº§è·¯å¾„ä¸­æå–
                    try:
                        hierarchy_options = self._extract_options_from_hierarchy(results, max_options, context)
                        if hierarchy_options and len(hierarchy_options) >= min_options:
                            # å¦‚æœå±‚çº§æå–æˆåŠŸï¼Œä½¿ç”¨å±‚çº§é€‰é¡¹
                            options = hierarchy_options
                            option_type = "brand_model"  # æ›´æ–°é€‰é¡¹ç±»å‹
                    except:
                        pass
            
            # ä¼˜åŒ–é€‰é¡¹ï¼ˆå»é‡ã€æ’åºï¼‰
            # IMPORTANT: options may already carry exact ids. When ids are present,
            # we must keep count == len(ids) and ensure â€œå…¶ä»–â€é—­åˆã€‚
            options = self._finalize_options_with_ids(
                option_type=option_type,
                options=options,
                results=results,
                max_options=max_options,
                context=context,
            )
            
            # æ£€æŸ¥é€‰é¡¹æ•°é‡æ˜¯å¦è¶³å¤Ÿ
            if options and len(options) >= min_options:
                # å¦‚æœé€‰é¡¹æ•°é‡>=10ï¼Œå°è¯•è¿›è¡Œæ–‡ä»¶åå‰ç¼€åˆå¹¶
                # æ³¨æ„ï¼šåªå¯¹åŸºäºæ–‡ä»¶åçš„é€‰é¡¹ç±»å‹è¿›è¡Œåˆå¹¶ï¼ˆé¿å…å½±å“å“ç‰Œã€å‹å·ç­‰ç»“æ„åŒ–é€‰é¡¹ï¼‰
                if len(options) >= 10:
                    # å°è¯•åŸºäºæ–‡ä»¶åå‰ç¼€åˆå¹¶
                    merged_options = self._merge_filename_prefixes(results, options, max_options=max_options)
                    if merged_options and len(merged_options) < len(options) and len(merged_options) >= min_options:
                        options = merged_options
                        option_type = "filename_prefix"
                
                # ä½¿ç”¨LLMç”Ÿæˆé—®é¢˜æ–‡æœ¬ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if use_llm:
                    try:
                        question_text = self.llm_service.generate_question_text(
                            option_type=option_type,
                            options=options,
                            total_count=len(results),
                            context=context
                        )
                    except Exception as e:
                        print(f"âš ï¸ LLMç”Ÿæˆé—®é¢˜å¤±è´¥: {str(e)}ï¼Œä½¿ç”¨é»˜è®¤æ¨¡æ¿")
                        question_text = self._generate_question_text(option_type, len(results), context)
                else:
                    question_text = self._generate_question_text(option_type, len(results), context)

                # ç»Ÿä¸€é¦–è½®æé—®å£å¾„ï¼šå¿…é¡»å¸¦ä¸Šç”¨æˆ·æŸ¥è¯¢/æ„å›¾ï¼Œå½¢å¦‚â€œæˆ‘æ‰¾åˆ°äº†XXç›¸å…³çš„æ•°æ®ã€‚è¯·é—®æ‚¨éœ€è¦çš„æ˜¯ï¼šâ€
                if not ((context or {}).get("filter_history")):
                    question_text = self._normalize_first_question_text(question_text, context)
                
                # ä»…å¯¹â€œæ–‡ä»¶åç±»â€é€‰é¡¹åšç›¸ä¼¼åˆå¹¶ï¼šé¿å…æ˜æ˜¾é‡å¤/ä»…ç»†èŠ‚å·®å¼‚çš„æ¡ç›®åˆ·å±
                # æ³¨æ„ï¼šä¸å¼ºè¡ŒæŠŠæ•°é‡å‹åˆ° <= 5ï¼›åªåœ¨ options è¶³å¤Ÿå¤šæ—¶å¯ç”¨ï¼ˆ>5ï¼‰
                if option_type in ("document_category", "filename_prefix") and len(options) >= 6:
                    options = merge_similar_options(
                        options,
                        enabled_min_len=6,
                        similarity_threshold=0.5,
                        name_key="name",
                    )

                option_labels = self._make_option_labels(min(max_options, len(options)))
                formatted_options = []
                for i, option in enumerate(options[:max_options]):
                    formatted_options.append({
                        "label": option_labels[i],
                        "name": option['name'],
                        "count": int(option.get("count") or 0),
                        "type": option_type,
                        # Optional: exact ids for this bucket (used for precise filtering)
                        "ids": option.get("ids") if isinstance(option, dict) else None,
                    })
                
                return {
                    "question": question_text,
                    "options": formatted_options,
                    "option_type": option_type
                }
        
        # å¦‚æœæ— æ³•ç”Ÿæˆé—®é¢˜ï¼Œå°è¯•æœ€åçš„fallback
        if not results or len(results) < min_options:
            return None
        
        # å¦‚æœç»“æœæ•°é‡>=10ï¼Œå°è¯•æ–‡ä»¶åå‰ç¼€åˆå¹¶
        if len(results) >= 10:
            # å…ˆåŸºäºæ–‡ä»¶åç”Ÿæˆé€‰é¡¹
            filename_options = []
            for result in results:
                file_name = result.diagram.file_name or ""
                filename_options.append({
                    "name": file_name,
                    "count": 1,
                    "ids": [result.diagram.id]
                })
            
            # å°è¯•åˆå¹¶æ–‡ä»¶åå‰ç¼€
            merged_options = self._merge_filename_prefixes(results, filename_options, max_options=max_options)
            if merged_options and len(merged_options) >= min_options:
                if len(merged_options) >= 6:
                    merged_options = merge_similar_options(
                        merged_options,
                        enabled_min_len=6,
                        similarity_threshold=0.5,
                        name_key="name",
                    )
                question_text = self._generate_question_text("filename_prefix", len(results), context)
                option_labels = self._make_option_labels(min(max_options, len(merged_options)))
                formatted_options = []
                for i, option in enumerate(merged_options[:max_options]):
                    formatted_options.append({
                        "label": option_labels[i],
                        "name": option['name'],
                        "count": int(option.get("count") or 0),
                        "type": "filename_prefix",
                        "ids": option.get("ids") if isinstance(option, dict) else None,
                    })
                return {
                    "question": question_text,
                    "options": formatted_options,
                    "option_type": "filename_prefix"
                }
        
        # æœ€åçš„fallbackï¼šä»å±‚çº§è·¯å¾„ä¸­æå–å“ç‰Œ+å‹å·ç»„åˆ
        try:
            fallback_options = self._extract_options_from_hierarchy(results, max_options, context)
            if fallback_options and len(fallback_options) >= min_options:
                # ä½¿ç”¨é»˜è®¤æ¨¡æ¿ç”Ÿæˆé—®é¢˜
                question_text = self._generate_question_text("brand_model", len(results), context)
                
                option_labels = self._make_option_labels(min(max_options, len(fallback_options)))
                formatted_options = []
                for i, option in enumerate(fallback_options[:max_options]):
                    formatted_options.append({
                        "label": option_labels[i],
                        "name": option['name'],
                        "count": option['count'],
                        "type": "brand_model"
                    })
                
                return {
                    "question": question_text,
                    "options": formatted_options,
                    "option_type": "brand_model"
                }
        except Exception as e:
            print(f"âš ï¸ Fallbacké€‰é¡¹æå–å¤±è´¥: {str(e)}")
        
        # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œè¿”å›None
        return None

    def _normalize_first_question_text(
        self,
        question_text: str,
        context: Optional[Dict[str, Any]] = None,
    ) -> str:
        """
        Ensure the first turn question explicitly mentions the user's query/intent,
        e.g. â€œæˆ‘æ‰¾åˆ°äº†C81ç”µè·¯å›¾ç›¸å…³çš„æ•°æ®ã€‚è¯·é—®æ‚¨éœ€è¦çš„æ˜¯ï¼šâ€
        """
        ctx = context or {}
        has_user_filters = bool(ctx.get("has_user_filters")) or bool(ctx.get("user_filter_history"))
        subject = self._extract_first_question_subject(ctx)
        desired = f"æˆ‘æ‰¾åˆ°äº†{subject}ç›¸å…³çš„æ•°æ®ã€‚è¯·é—®æ‚¨éœ€è¦çš„æ˜¯ï¼š"

        # ä»…åœ¨â€œç”¨æˆ·å°šæœªåšå‡ºå®é™…ç­›é€‰â€æ—¶å¼ºåˆ¶é¦–è½®æ¨¡æ¿ï¼›é¿å…è¦†ç›–åç»­è¿½é—®çš„æ–‡æœ¬
        if has_user_filters:
            return question_text or desired
        if not question_text:
            return desired
        # è‹¥ç°æœ‰æ–‡æœ¬æœªåŒ…å«â€œæˆ‘æ‰¾åˆ°äº†â€æˆ–æœªåŒ…å«ä¸»ä½“ä¿¡æ¯ï¼Œåˆ™æ”¹ç”¨æ ‡å‡†æ¨¡æ¿
        if ("æˆ‘æ‰¾åˆ°äº†" not in question_text) or (subject and subject not in question_text):
            return desired
        return question_text

    def _extract_first_question_subject(
        self,
        context: Optional[Dict[str, Any]] = None,
    ) -> str:
        """
        Decide what to display as the subject in the first-turn question.
        Priority: explicit user query (å«å‹å·/ä»£å·) -> intent brand+model -> brand -> model -> fallback.
        """
        ctx = context or {}
        intent_ctx = ctx.get("intent_result") or {}

        # ç”¨æˆ·åŸå§‹æŸ¥è¯¢ï¼šä¼˜å…ˆä¿ç•™åŒ…å«ä»£å·/æ•°å­—çš„è¡¨è¾¾ï¼ˆå¦‚ C81ã€ç”µè·¯å›¾ï¼‰
        current_query = (ctx.get("current_query") or "").strip()
        current_query = re.sub(r"[ï¼Œã€‚.\s]+$", "", current_query)
        if current_query:
            # åŒ…å«å­—æ¯æˆ–æ•°å­—æ—¶ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹æŸ¥è¯¢ä»¥é¿å…è¢«å“ç‰Œè¦†ç›–
            if re.search(r"[A-Za-z0-9]", current_query):
                return current_query

        subject = None
        intent_brand = (intent_ctx.get("brand") or "").strip()
        intent_model = (intent_ctx.get("model") or "").strip()

        if intent_brand and intent_model:
            subject = f"{intent_brand}{intent_model}"
        elif intent_brand:
            subject = intent_brand
        elif intent_model:
            subject = intent_model
        elif current_query:
            subject = current_query
        else:
            subject = "ç›¸å…³ç”µè·¯å›¾"

        # ç®€å•æ¸…ç†æœ«å°¾çš„æ— ç”¨ç¬¦å·
        subject = re.sub(r"[ï¼Œã€‚.\s]+$", "", subject)
        return subject or "ç›¸å…³ç”µè·¯å›¾"

    def _extract_disjoint_type_options(
        self,
        results: List[ScoredResult],
        max_options: int = 5,
    ) -> List[Dict]:
        """
        Disjoint type buckets based on diagram.diagram_type.
        Each diagram belongs to at most one bucket.
        """
        type_to_ids: Dict[str, set] = {}
        for r in results:
            d = r.diagram
            t = (getattr(d, "diagram_type", None) or "").replace("*", "").strip()
            if not t:
                t = "å…¶ä»–ï¼ˆæœªæ ‡æ³¨ç±»å‹ï¼‰"
            type_to_ids.setdefault(t, set()).add(d.id)
        options = [{"name": k, "count": len(v), "ids": sorted(v)} for k, v in type_to_ids.items()]
        options.sort(key=lambda x: (-x["count"], x["name"]))
        return options[: max(1, max_options * 5)]

    def _finalize_options_with_ids(
        self,
        option_type: str,
        options: List[Dict],
        results: List[ScoredResult],
        max_options: int,
        context: Optional[Dict[str, Any]] = None,
    ) -> List[Dict]:
        """
        Normalize/merge options and ensure:
        - each option has ids
        - count == len(ids)
        - append â€œå…¶ä»–ï¼ˆæœªåˆ†ç±»/æ›´å¤šï¼‰â€ to close coverage when truncated
        """
        if not options:
            return []

        # Build mapping name -> ids (prefer provided ids; otherwise compute via disjoint field buckets)
        all_ids = {r.diagram.id for r in results}

        def norm_name(s: str) -> str:
            if not s:
                return ""
            s = str(s).replace("*", "").strip()
            s = re.sub(r"\s+", " ", s)
            s = re.sub(r"(ç³»åˆ—)\s*(ç³»åˆ—)+", r"\1", s)
            return s.strip()

        merged: Dict[str, set] = {}

        # Fast paths: if options already have ids, just merge by normalized name
        has_any_ids = any(isinstance(o, dict) and isinstance(o.get("ids"), list) for o in options)
        if has_any_ids:
            for o in options:
                name = norm_name(o.get("name"))
                ids = o.get("ids") or []
                if not name:
                    continue
                merged.setdefault(name, set()).update(ids)
        else:
            # Fallback: compute ids from parsed fields for disjoint types where possible
            # brand/model/category/brand_model use parsed fields => disjoint buckets, stable counts
            opt = (option_type or "").strip().lower()
            if opt in ("brand", "model", "category", "vehicle_category", "brand_model", "brand+model"):
                for r in results:
                    d = r.diagram
                    if opt == "brand":
                        key = (d.brand or "").strip() or "å…¶ä»–ï¼ˆæœªæ ‡æ³¨å“ç‰Œï¼‰"
                    elif opt == "model":
                        key = (d.model or "").strip() or "å…¶ä»–ï¼ˆæœªæ ‡æ³¨å‹å·/ç³»åˆ—ï¼‰"
                    elif opt in ("category", "vehicle_category"):
                        key = (getattr(d, "vehicle_category", None) or "").strip() or "å…¶ä»–ï¼ˆæœªæ ‡æ³¨ç±»åˆ«ï¼‰"
                    else:
                        b = (d.brand or "").strip()
                        m = (d.model or "").strip()
                        if b and m:
                            key = f"{b} {m}"
                        elif b:
                            key = b
                        elif m:
                            key = m
                        else:
                            key = "å…¶ä»–ï¼ˆæœªæ ‡æ³¨å“ç‰Œ/å‹å·ï¼‰"
                    key = norm_name(key)
                    merged.setdefault(key, set()).add(d.id)
            elif opt == "type":
                for r in results:
                    d = r.diagram
                    key = (getattr(d, "diagram_type", None) or "").strip() or "å…¶ä»–ï¼ˆæœªæ ‡æ³¨ç±»å‹ï¼‰"
                    key = norm_name(key)
                    merged.setdefault(key, set()).add(d.id)
            else:
                # Unknown: keep original counts, but without ids we cannot guarantee consistency
                # (still better to return as-is)
                return self.optimize_options(options, max_options)

        # Convert to list with ids
        items = [{"name": k, "ids": sorted(v), "count": len(v)} for k, v in merged.items() if k]
        items.sort(key=lambda x: (-x["count"], x["name"]))

        # Remove non-discriminating buckets: options that cover the entire candidate set
        # These lead to "23 â†’ 23" no-op selections and can trap users in non-converging loops.
        if all_ids:
            items = [it for it in items if set(it.get("ids") or []) != all_ids]

        # Apply truncation with â€œå…¶ä»–â€ closure (only when there are more than max_options buckets)
        if max_options <= 0:
            return []

        if len(items) <= max_options:
            return items

        head_limit = max_options - 1 if max_options >= 3 else max_options
        head = items[:head_limit]
        used = set()
        for it in head:
            used |= set(it["ids"])
        rest = all_ids - used
        if rest and head_limit < max_options:
            head.append({"name": "å…¶ä»–ï¼ˆæœªåˆ†ç±»/æ›´å¤šï¼‰", "ids": sorted(rest), "count": len(rest)})
        head.sort(key=lambda x: (-x["count"], x["name"]))
        return head[:max_options]

    def _extract_config_variants(
        self,
        results: List[ScoredResult],
        max_options: int = 5,
        context: Optional[Dict[str, Any]] = None
    ) -> List[Dict]:
        """
        æå–â€œé…ç½®/è½´å‹/ç”¨é€”â€ç­‰é€‰é¡¹ï¼ˆå¦‚ 4x2/6x2/6x4 + ç‰µå¼•è½¦/è½½è´§è½¦/è‡ªå¸è½¦/ç¯å«è½¦ ç­‰ï¼‰
        ç”¨äºç¬¬äºŒå±‚æ¾„æ¸…ã€‚
        """
        import re
        from backend.app.services.search_service import SearchService

        def norm(s: str) -> str:
            return SearchService._norm_text(s)

        role_keywords = ["ç‰µå¼•è½¦", "è½½è´§è½¦", "è‡ªå¸è½¦", "ç¯å«è½¦", "æ…æ‹Œè½¦", "ä¸“ç”¨è½¦", "å¢å¼", "å·¥ç¨‹è½¦", "å†·è—è½¦"]
        options: Dict[str, int] = {}

        for r in results:
            d = r.diagram
            text = " ".join([d.file_name or ""] + (d.hierarchy_path or []))
            t = norm(text)
            if not t:
                continue

            # è½´å‹/é©±åŠ¨ï¼š4x2 / 6x2 / 6x4 / 8x4 ç­‰
            axle = None
            m = re.search(r"(\d)\s*[xX]\s*(\d)", text)
            if m:
                axle = f"{m.group(1)}x{m.group(2)}"
            else:
                # å…¼å®¹ â€œ6X4â€å†™æ³•ï¼ˆå¤§å°å†™ï¼‰
                m2 = re.search(r"(\d)\s*[Xx]\s*(\d)", text)
                if m2:
                    axle = f"{m2.group(1)}x{m2.group(2)}"

            role = None
            for kw in role_keywords:
                if norm(kw) in t:
                    role = kw
                    break

            if axle and role:
                name = f"{axle} {role}"
            elif axle:
                name = axle
            elif role:
                name = role
            else:
                continue

            options[name] = options.get(name, 0) + 1

        out = [{"name": k, "count": v} for k, v in options.items()]
        out.sort(key=lambda x: (-x["count"], x["name"]))
        return out[:max_options]
    
    def _extract_brand_model_options(
        self,
        results: List[ScoredResult],
        max_options: int = 5
    ) -> List[Dict]:
        """
        æå–å“ç‰Œ+å‹å·ç»„åˆé€‰é¡¹
        
        Args:
            results: æœç´¢ç»“æœåˆ—è¡¨
            max_options: æœ€å¤§é€‰é¡¹æ•°é‡
            
        Returns:
            é€‰é¡¹åˆ—è¡¨
        """
        from backend.app.utils.hierarchy_util import HierarchyUtil
        
        diagrams = [result.diagram for result in results]
        return HierarchyUtil.extract_options(diagrams, "brand_model", max_options)
    
    def _extract_options_from_hierarchy(
        self,
        results: List[ScoredResult],
        max_options: int = 5,
        context: Optional[Dict[str, Any]] = None
    ) -> List[Dict]:
        """
        ä»å±‚çº§è·¯å¾„ä¸­æå–é€‰é¡¹ï¼ˆç”¨äºç”Ÿæˆé€‰æ‹©é¢˜ï¼‰
        ä¼˜å…ˆæå–å“ç‰Œåé¢çš„ç³»åˆ—ä¿¡æ¯ï¼ˆå¦‚KLã€KCç­‰ï¼‰
        
        Args:
            results: æœç´¢ç»“æœåˆ—è¡¨
            max_options: æœ€å¤§é€‰é¡¹æ•°é‡
            
        Returns:
            é€‰é¡¹åˆ—è¡¨
        """
        from backend.app.utils.hierarchy_util import HierarchyUtil
        
        diagrams = [result.diagram for result in results]
        option_counts: Dict[str, int] = {}
        option_ids: Dict[str, set] = {}
        
        # ä»ä¸Šä¸‹æ–‡ä¸­è·å–ç”¨æˆ·æ„å›¾çš„å“ç‰Œï¼ˆå¯èƒ½æ˜¯å¤åˆå“ç‰Œï¼‰
        user_brand = None
        if context and context.get("intent_result"):
            user_brand = context["intent_result"].get("brand")
        elif context and context.get("filter_history"):
            for filter_item in context["filter_history"]:
                if filter_item.get("type") == "brand":
                    user_brand = filter_item.get("value")
                    break
        
        for diagram in diagrams:
            # æŸ¥æ‰¾å“ç‰Œåœ¨å±‚çº§è·¯å¾„ä¸­çš„ä½ç½®ï¼ˆæ”¯æŒå¤åˆå“ç‰Œï¼‰
            brand_pos = -1
            series_pos = -1
            
            # é¦–å…ˆå°è¯•ä½¿ç”¨ç”¨æˆ·æ„å›¾çš„å“ç‰Œï¼ˆå¯èƒ½æ˜¯å¤åˆå“ç‰Œï¼‰
            if user_brand:
                # å¦‚æœç”¨æˆ·å“ç‰Œæ˜¯å¤åˆå“ç‰Œï¼ˆå¦‚"ä¸œé£å¤©é¾™"ï¼‰ï¼Œå°è¯•åŒ¹é…å±‚çº§è·¯å¾„
                if user_brand in HierarchyUtil.COMPOUND_BRANDS:
                    # æå–åŸºç¡€å“ç‰Œï¼ˆå¦‚"ä¸œé£"ï¼‰
                    base_brand = None
                    series_keyword = None
                    if "ä¸œé£" in user_brand:
                        base_brand = "ä¸œé£"
                        if "å¤©é¾™" in user_brand:
                            series_keyword = "å¤©é¾™"
                    elif "è§£æ”¾" in user_brand:
                        base_brand = "è§£æ”¾"
                    elif "é‡æ±½" in user_brand:
                        base_brand = "é‡æ±½"
                    elif "ç¦ç”°" in user_brand:
                        base_brand = "ç¦ç”°"
                    elif "çº¢å²©" in user_brand:
                        base_brand = "çº¢å²©"
                    
                    # åœ¨å±‚çº§è·¯å¾„ä¸­æŸ¥æ‰¾åŸºç¡€å“ç‰Œ
                    if base_brand:
                        for i, level in enumerate(diagram.hierarchy_path):
                            if base_brand in level or level == base_brand:
                                brand_pos = i
                                # å¦‚æœæ‰¾åˆ°äº†åŸºç¡€å“ç‰Œï¼ŒæŸ¥æ‰¾åŒ…å«ç³»åˆ—å…³é”®è¯çš„å±‚çº§
                                if series_keyword:
                                    for j in range(i + 1, len(diagram.hierarchy_path)):
                                        if series_keyword in diagram.hierarchy_path[j]:
                                            series_pos = j
                                            break
                                break
                else:
                    # å¦‚æœä¸æ˜¯å¤åˆå“ç‰Œï¼Œç›´æ¥åŒ¹é…
                    for i, level in enumerate(diagram.hierarchy_path):
                        if user_brand in level or level == user_brand:
                            brand_pos = i
                            break
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨diagram.brandï¼ˆå¯èƒ½æ˜¯ä»å±‚çº§è·¯å¾„è§£æå‡ºæ¥çš„ï¼‰
            if brand_pos == -1 and diagram.brand:
                for i, level in enumerate(diagram.hierarchy_path):
                    if diagram.brand in level or level == diagram.brand:
                        brand_pos = i
                        break
            
            # ç¡®å®šè¦æå–çš„å±‚çº§ä½ç½®
            # å±‚çº§è·¯å¾„ç»“æ„ï¼šç”µè·¯å›¾ -> ç±»å‹ -> å“ç‰Œ -> ç³»åˆ—å±‚çº§ -> å…·ä½“ç³»åˆ—ï¼ˆå¦‚å¤©é¾™KLï¼‰ -> ...
            extract_pos = -1
            if brand_pos != -1:
                # æŸ¥æ‰¾å“ç‰Œåé¢çš„å±‚çº§ï¼Œä¼˜å…ˆæŸ¥æ‰¾åŒ…å«ç³»åˆ—ä»£ç çš„å±‚çº§
                # å…ˆæŸ¥æ‰¾"ç³»åˆ—"ç›¸å…³çš„å±‚çº§ï¼ˆå¦‚"å¤©é¾™*ç³»åˆ—"æˆ–"å¤©é¾™KLç³»åˆ—"ï¼‰
                for i in range(brand_pos + 1, len(diagram.hierarchy_path)):
                    level = diagram.hierarchy_path[i]
                    level_clean = level.replace('*', '').strip()
                    
                    # å¦‚æœå±‚çº§åŒ…å«"ç³»åˆ—"å…³é”®è¯ï¼Œä¼˜å…ˆä½¿ç”¨
                    if "ç³»åˆ—" in level_clean:
                        # æ£€æŸ¥å½“å‰å±‚çº§æ˜¯å¦åŒ…å«ç³»åˆ—ä»£ç ï¼ˆå¦‚"å¤©é¾™KLç³»åˆ—"ï¼‰
                        series_match = re.search(r'([A-Z]{2,3})', level_clean)
                        if series_match:
                            potential_code = series_match.group(1)
                            if potential_code not in ['ECU', 'DCI', 'LNG', 'EDC', 'VEC', 'DOC', 'DCM', 'DOCX', 'VECU', 'BCM']:
                                extract_pos = i
                                break
                        # å¦‚æœå½“å‰å±‚çº§ä¸åŒ…å«ç³»åˆ—ä»£ç ï¼Œæ£€æŸ¥ä¸‹ä¸€å±‚
                        if i + 1 < len(diagram.hierarchy_path):
                            next_level = diagram.hierarchy_path[i + 1]
                            next_level_clean = next_level.replace('*', '').strip()
                            # å¦‚æœä¸‹ä¸€å±‚åŒ…å«ç³»åˆ—ä»£ç ï¼ˆå¦‚KLã€KCç­‰ï¼‰ï¼Œä½¿ç”¨ä¸‹ä¸€å±‚
                            series_match = re.search(r'([A-Z]{2,3})', next_level_clean)
                            if series_match:
                                potential_code = series_match.group(1)
                                if potential_code not in ['ECU', 'DCI', 'LNG', 'EDC', 'VEC', 'DOC', 'DCM', 'DOCX', 'VECU', 'BCM']:
                                    extract_pos = i + 1
                                    break
                        # å¦åˆ™ä½¿ç”¨å½“å‰å±‚çº§
                        if extract_pos == -1:
                            extract_pos = i
                        break
                    
                    # å¦‚æœå±‚çº§åŒ…å«"å¤©é¾™"ä¸”åŒ…å«ç³»åˆ—ä»£ç ï¼ˆå¦‚"å¤©é¾™KL"ï¼‰
                    if user_brand and "å¤©é¾™" in user_brand and "å¤©é¾™" in level_clean:
                        series_match = re.search(r'([A-Z]{2,3})', level_clean)
                        if series_match:
                            potential_code = series_match.group(1)
                            if potential_code not in ['ECU', 'DCI', 'LNG', 'EDC', 'VEC', 'DOC', 'DCM', 'DOCX', 'VECU', 'BCM']:
                                extract_pos = i
                                break
                
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç³»åˆ—å±‚çº§ï¼ŒæŸ¥æ‰¾å“ç‰Œåé¢ç¬¬ä¸€ä¸ªåŒ…å«ç³»åˆ—ä»£ç çš„å±‚çº§
                if extract_pos == -1:
                    for i in range(brand_pos + 1, len(diagram.hierarchy_path)):
                        level = diagram.hierarchy_path[i]
                        level_clean = level.replace('*', '').strip()
                        # è·³è¿‡ç±»å‹ç›¸å…³çš„å±‚çº§
                        type_keywords = ['ç”µè·¯å›¾', 'ä»ªè¡¨', 'ECU', 'æ•´è½¦', 'çº¿è·¯', 'é’ˆè„š', 'æ¨¡å—']
                        if any(keyword in level_clean for keyword in type_keywords):
                            continue
                        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç³»åˆ—ä»£ç 
                        series_match = re.search(r'([A-Z]{2,3})', level_clean)
                        if series_match:
                            potential_code = series_match.group(1)
                            if potential_code not in ['ECU', 'DCI', 'LNG', 'EDC', 'VEC', 'DOC', 'DCM', 'DOCX', 'VECU', 'BCM']:
                                extract_pos = i
                                break
                
                # å¦‚æœä»ç„¶æ²¡æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨å“ç‰Œåé¢çš„ç¬¬ä¸€ä¸ªéç±»å‹å±‚çº§
                if extract_pos == -1 and brand_pos + 1 < len(diagram.hierarchy_path):
                    for i in range(brand_pos + 1, len(diagram.hierarchy_path)):
                        level = diagram.hierarchy_path[i]
                        level_clean = level.replace('*', '').strip()
                        # è·³è¿‡ç±»å‹ç›¸å…³çš„å±‚çº§
                        type_keywords = ['ç”µè·¯å›¾', 'ä»ªè¡¨', 'ECU', 'æ•´è½¦', 'çº¿è·¯', 'é’ˆè„š', 'æ¨¡å—']
                        if not any(keyword in level_clean for keyword in type_keywords):
                            extract_pos = i
                            break
            
            # æå–ç³»åˆ—ä¿¡æ¯
            if extract_pos != -1 and extract_pos < len(diagram.hierarchy_path):
                level_value = diagram.hierarchy_path[extract_pos]
                # æ¸…ç†å±‚çº§å€¼ï¼ˆå»é™¤ç‰¹æ®Šå­—ç¬¦ï¼‰
                level_value_clean = level_value.replace('*', '').strip()
                
                # è·³è¿‡ç±»å‹ç›¸å…³çš„å±‚çº§
                type_keywords = ['ç”µè·¯å›¾', 'ä»ªè¡¨', 'ECU', 'æ•´è½¦', 'çº¿è·¯', 'é’ˆè„š', 'æ¨¡å—']
                if any(keyword in level_value_clean for keyword in type_keywords):
                    # å¦‚æœå±‚çº§å€¼åŒ…å«ç±»å‹å…³é”®è¯ï¼Œå°è¯•æå–æ›´åé¢çš„å±‚çº§
                    if extract_pos + 1 < len(diagram.hierarchy_path):
                        level_value = diagram.hierarchy_path[extract_pos + 1]
                        level_value_clean = level_value.replace('*', '').strip()
                
                # æå–ç³»åˆ—ä»£ç ï¼ˆå¦‚KLã€KCã€VLç­‰ï¼‰
                # å°è¯•ä»å¤šä¸ªæ¥æºæå–ç³»åˆ—ä¿¡æ¯
                series_code = None
                
                # å®šä¹‰éœ€è¦æ’é™¤çš„éç³»åˆ—ä»£ç å…³é”®è¯ï¼ˆæ–‡ä»¶æ‰©å±•åã€ECUç±»å‹ç­‰ï¼‰
                excluded_codes = [
                    'ECU', 'DCI', 'LNG', 'EDC', 'VEC', 'DOC', 'DCM', 
                    'DOCX', 'VECU', 'BCM', 'PDF', 'XLS', 'XLSX', 'PPT', 'PPTX',
                    'D31', 'D32', 'D53', 'D56', 'ABS', 'ESP', 'TCS', 'EBD',
                    'CAN', 'LIN', 'MOST', 'FLEX', 'KWP', 'UDS', 'OBD'
                ]
                
                # 1. ä¼˜å…ˆä»å±‚çº§å€¼ä¸­æå–ç³»åˆ—ä»£ç ï¼ˆå¦‚"å¤©é¾™KL" -> "KL"ï¼‰
                if level_value_clean:
                    # å¦‚æœå±‚çº§å€¼åŒ…å«å“ç‰Œåç§°ï¼ˆå¦‚"å¤©é¾™"ï¼‰ï¼Œæå–åé¢çš„ç³»åˆ—ä»£ç 
                    if user_brand and "å¤©é¾™" in user_brand:
                        # æŸ¥æ‰¾"å¤©é¾™"åé¢çš„ç³»åˆ—ä»£ç 
                        if "å¤©é¾™" in level_value_clean:
                            after_tianlong = level_value_clean.split("å¤©é¾™", 1)[1] if "å¤©é¾™" in level_value_clean else level_value_clean
                            # æå–ç³»åˆ—ä»£ç ï¼ˆä¼˜å…ˆåŒ¹é…2-3ä¸ªå¤§å†™å­—æ¯ï¼Œå¦‚KLã€KCã€VLï¼‰
                            series_match = re.search(r'([A-Z]{2,3})', after_tianlong)
                            if series_match:
                                potential_code = series_match.group(1)
                                if potential_code not in excluded_codes:
                                    series_code = potential_code
                    
                    # ç›´æ¥æŸ¥æ‰¾2-3ä¸ªå¤§å†™å­—æ¯ï¼ˆç³»åˆ—ä»£ç ï¼Œå¦‚KLã€KCã€VLï¼‰
                    if not series_code:
                        # ä¼˜å…ˆåŒ¹é…2-3ä¸ªå¤§å†™å­—æ¯ï¼ˆç³»åˆ—ä»£ç é€šå¸¸æ˜¯2-3ä¸ªå­—æ¯ï¼‰
                        series_match = re.search(r'([A-Z]{2,3})', level_value_clean)
                        if series_match:
                            potential_code = series_match.group(1)
                            # æ’é™¤å¸¸è§çš„éç³»åˆ—ä»£ç 
                            if potential_code not in excluded_codes:
                                series_code = potential_code
                    
                    # å¦‚æœå±‚çº§å€¼åŒ…å«"ç³»åˆ—"å…³é”®è¯ï¼Œå°è¯•æå–ç³»åˆ—åç§°
                    if "ç³»åˆ—" in level_value_clean and not series_code:
                        # æå–"ç³»åˆ—"å‰é¢çš„éƒ¨åˆ†ä½œä¸ºç³»åˆ—åç§°
                        series_part = level_value_clean.split("ç³»åˆ—")[0].strip()
                        if series_part and len(series_part) <= 10:
                            # æ£€æŸ¥æ˜¯å¦æ˜¯ç³»åˆ—ä»£ç æ ¼å¼ï¼ˆ2-3ä¸ªå¤§å†™å­—æ¯ï¼‰
                            series_match = re.search(r'([A-Z]{2,3})', series_part)
                            if series_match:
                                potential_code = series_match.group(1)
                                if potential_code not in excluded_codes:
                                    series_code = potential_code
                            else:
                                # å¦‚æœä¸æ˜¯ç³»åˆ—ä»£ç æ ¼å¼ï¼Œä½¿ç”¨æ•´ä¸ªéƒ¨åˆ†
                                series_code = series_part
                
                # 2. å¦‚æœä»å±‚çº§è·¯å¾„ä¸­æå–ä¸åˆ°ï¼Œå°è¯•ä»æ–‡ä»¶åä¸­æå–ï¼ˆä½†è¦æ’é™¤æ–‡ä»¶æ‰©å±•åï¼‰
                if not series_code and diagram.file_name:
                    file_name = diagram.file_name
                    # å»é™¤æ–‡ä»¶æ‰©å±•åï¼ˆ.DOCXã€.PDFç­‰ï¼‰
                    file_name_without_ext = re.sub(r'\.[A-Z]{2,5}$', '', file_name, flags=re.IGNORECASE)
                    
                    # æŸ¥æ‰¾æ–‡ä»¶åä¸­çš„ç³»åˆ—ä»£ç ï¼ˆå¦‚"ä¸œé£å¤©é¾™KL..." -> "KL"ï¼‰
                    # å…ˆæŸ¥æ‰¾å“ç‰Œåé¢çš„éƒ¨åˆ†
                    if user_brand:
                        brand_in_file = user_brand
                    elif diagram.brand:
                        brand_in_file = diagram.brand
                    else:
                        brand_in_file = "ä¸œé£"
                    
                    if brand_in_file in file_name_without_ext:
                        after_brand = file_name_without_ext.split(brand_in_file, 1)[1] if brand_in_file in file_name_without_ext else file_name_without_ext
                        # æå–2-3ä¸ªå¤§å†™å­—æ¯ï¼ˆç³»åˆ—ä»£ç ï¼‰
                        # åªæ£€æŸ¥å“ç‰Œåé¢çš„å‰30ä¸ªå­—ç¬¦ï¼Œé¿å…æå–åˆ°æ–‡ä»¶æ‰©å±•åæˆ–ECUç±»å‹
                        series_match = re.search(r'([A-Z]{2,3})', after_brand[:30])
                        if series_match:
                            potential_code = series_match.group(1)
                            # æ’é™¤æ–‡ä»¶æ‰©å±•åå’ŒECUç±»å‹
                            if potential_code not in excluded_codes:
                                series_code = potential_code
                
                # 3. å¦‚æœæå–åˆ°äº†ç³»åˆ—ä»£ç ï¼Œç”Ÿæˆé€‰é¡¹
                if series_code:
                    display_brand = user_brand if user_brand else (diagram.brand or "ä¸œé£")
                    option_name = f"{display_brand} {series_code} ç³»åˆ—"
                    option_counts[option_name] = option_counts.get(option_name, 0) + 1
                    option_ids.setdefault(option_name, set()).add(diagram.id)
                elif level_value_clean and level_value_clean != diagram.brand and len(level_value_clean) <= 15:
                    # å¦‚æœæ²¡æœ‰æå–åˆ°ç³»åˆ—ä»£ç ï¼Œä½†å±‚çº§å€¼æœ‰æ„ä¹‰ï¼Œä½¿ç”¨å±‚çº§å€¼
                    # è·³è¿‡ç±»å‹ç›¸å…³çš„å±‚çº§
                    type_keywords = ['ç”µè·¯å›¾', 'ä»ªè¡¨', 'ECU', 'æ•´è½¦', 'çº¿è·¯', 'é’ˆè„š', 'æ¨¡å—']
                    if not any(keyword in level_value_clean for keyword in type_keywords):
                        display_brand = user_brand if user_brand else (diagram.brand or "ä¸œé£")
                        option_name = f"{display_brand} {level_value_clean}"
                        option_counts[option_name] = option_counts.get(option_name, 0) + 1
                        option_ids.setdefault(option_name, set()).add(diagram.id)
        
        # å…³é”®ä¿®å¤ï¼š
        # - ä¸ºæ¯ä¸ªé€‰é¡¹æºå¸¦ç²¾ç¡® idsï¼Œåç»­ç­›é€‰ç›´æ¥æŒ‰ ids è¿‡æ»¤ï¼Œé¿å… â€œé€‰NTå´æ··å…¥MT/Nâ€ çš„ä¸ç²¾ç¡®é—®é¢˜
        # - åŠ å…¥ â€œå…¶ä»–/æœªåˆ†ç±»â€ æ¡¶ï¼Œè®©é€‰é¡¹ count èƒ½è¦†ç›–ä¸Šä¸€è½®æ€»æ•°ï¼ˆå³ä½¿è¢« max_options æˆªæ–­ï¼‰

        # å…ˆæŒ‰ count æ’åº
        sorted_names = [n for n, _ in sorted(option_counts.items(), key=lambda x: x[1], reverse=True)]
        total_ids = {d.id for d in diagrams}

        # é¢„ç•™ä¸€ä¸ªæ§½ä½ç»™ â€œå…¶ä»–â€ï¼Œä¿è¯ sums é—­åˆ
        head_limit = max_options
        reserve_other = True
        if reserve_other and head_limit >= 3:
            head_limit = max_options - 1

        chosen_names = sorted_names[:head_limit]
        chosen: List[Dict] = []
        used_ids = set()
        for name in chosen_names:
            ids = set(option_ids.get(name, set()))
            if not ids:
                # fallbackï¼šæ²¡æœ‰ ids è®°å½•æ—¶ä½¿ç”¨è®¡æ•°ï¼ˆä½†å°½é‡ä¸å‘ç”Ÿï¼‰
                continue
            used_ids |= ids
            chosen.append({"name": name, "count": len(ids), "ids": sorted(ids)})

        remaining_ids = total_ids - used_ids
        if reserve_other and remaining_ids:
            chosen.append({"name": "å…¶ä»–ï¼ˆæœªåˆ†ç±»/æ›´å¤šï¼‰", "count": len(remaining_ids), "ids": sorted(remaining_ids)})

        chosen.sort(key=lambda x: x["count"], reverse=True)
        return chosen[:max_options]

    def _extract_variant_options(
        self,
        results: List[ScoredResult],
        max_options: int = 5,
        context: Optional[Dict[str, Any]] = None,
    ) -> List[Dict]:
        """
        è½¦å‹å˜ä½“é€‰é¡¹ï¼šæŒ‰æ–‡ä»¶åå‰ç¼€ï¼ˆè½¦å‹/ç”¨é€”/è½´å‹/é…ç½®ç­‰ï¼‰åˆ†ç»„ã€‚
        å…¸å‹åœºæ™¯ï¼šç”¨æˆ·è¾“å…¥â€œå¤©é¾™KLç”µè·¯å›¾â€ï¼Œå¸Œæœ›å…ˆåœ¨ 5 ä¸ªå˜ä½“ä¸­é€‰ä¸€ä¸ªï¼Œå†ç›´æ¥ç»™ç»“æœã€‚
        """
        from backend.app.utils.variant_util import variant_key_for_query

        diagrams = [r.diagram for r in results]
        current_query = (context or {}).get("current_query") or ""

        counts: Dict[str, int] = {}
        for d in diagrams:
            k = variant_key_for_query(d.file_name or "", current_query)
            if not k:
                continue
            counts[k] = counts.get(k, 0) + 1

        options = [{"name": f"{k} ç³»åˆ—", "count": c} for k, c in sorted(counts.items(), key=lambda x: x[1], reverse=True)]
        return options[:max_options]
    
    def _extract_series_codes_aggressive(
        self,
        results: List[ScoredResult],
        max_options: int = 5,
        context: Optional[Dict[str, Any]] = None
    ) -> List[Dict]:
        """
        æ›´æ¿€è¿›åœ°ä»å±‚çº§è·¯å¾„å’Œæ–‡ä»¶åä¸­æå–ç³»åˆ—ä»£ç 
        ä¸é™åˆ¶ä½ç½®ï¼Œä»æ‰€æœ‰å¯èƒ½çš„å±‚çº§ä¸­æå–
        
        Args:
            results: æœç´¢ç»“æœåˆ—è¡¨
            max_options: æœ€å¤§é€‰é¡¹æ•°é‡
            context: å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            é€‰é¡¹åˆ—è¡¨
        """
        from backend.app.utils.hierarchy_util import HierarchyUtil
        
        diagrams = [result.diagram for result in results]
        option_counts = {}
        
        # ä»ä¸Šä¸‹æ–‡ä¸­è·å–ç”¨æˆ·æ„å›¾çš„å“ç‰Œ
        user_brand = None
        if context and context.get("intent_result"):
            user_brand = context["intent_result"].get("brand")
        elif context and context.get("filter_history"):
            for filter_item in context["filter_history"]:
                if filter_item.get("type") == "brand":
                    user_brand = filter_item.get("value")
                    break
        
        # å®šä¹‰éœ€è¦æ’é™¤çš„éç³»åˆ—ä»£ç å…³é”®è¯
        excluded_codes = [
            'ECU', 'DCI', 'LNG', 'EDC', 'VEC', 'DOC', 'DCM', 
            'DOCX', 'VECU', 'BCM', 'PDF', 'XLS', 'XLSX', 'PPT', 'PPTX',
            'D31', 'D32', 'D53', 'D56', 'ABS', 'ESP', 'TCS', 'EBD',
            'CAN', 'LIN', 'MOST', 'FLEX', 'KWP', 'UDS', 'OBD'
        ]
        
        # ä»æ‰€æœ‰å±‚çº§è·¯å¾„ä¸­æå–ç³»åˆ—ä»£ç 
        for diagram in diagrams:
            # éå†æ‰€æœ‰å±‚çº§è·¯å¾„ï¼ŒæŸ¥æ‰¾ç³»åˆ—ä»£ç 
            for level in diagram.hierarchy_path:
                level_clean = level.replace('*', '').strip()
                
                # è·³è¿‡ç±»å‹ç›¸å…³çš„å±‚çº§
                type_keywords = ['ç”µè·¯å›¾', 'ä»ªè¡¨', 'ECU', 'æ•´è½¦', 'çº¿è·¯', 'é’ˆè„š', 'æ¨¡å—']
                if any(keyword in level_clean for keyword in type_keywords):
                    continue
                
                # æŸ¥æ‰¾ç³»åˆ—ä»£ç ï¼ˆ2-3ä¸ªå¤§å†™å­—æ¯ï¼‰
                series_match = re.search(r'([A-Z]{2,3})', level_clean)
                if series_match:
                    potential_code = series_match.group(1)
                    if potential_code not in excluded_codes:
                        display_brand = user_brand if user_brand else (diagram.brand or "ä¸œé£")
                        option_name = f"{display_brand} {potential_code} ç³»åˆ—"
                        option_counts[option_name] = option_counts.get(option_name, 0) + 1
                        break  # æ‰¾åˆ°ä¸€ä¸ªå°±åœæ­¢ï¼Œé¿å…é‡å¤
        
        # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶æŒ‰æ•°é‡æ’åº
        options = [
            {"name": name, "count": count}
            for name, count in sorted(option_counts.items(), key=lambda x: x[1], reverse=True)
        ]
        
        return options[:max_options]
    
    def _extract_series_from_filenames(
        self,
        results: List[ScoredResult],
        max_options: int = 5,
        context: Optional[Dict[str, Any]] = None
    ) -> List[Dict]:
        """
        ä»æ–‡ä»¶åä¸­æå–ç³»åˆ—ä»£ç ï¼ˆæœ€åçš„fallbackï¼‰
        
        Args:
            results: æœç´¢ç»“æœåˆ—è¡¨
            max_options: æœ€å¤§é€‰é¡¹æ•°é‡
            context: å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            é€‰é¡¹åˆ—è¡¨
        """
        option_counts = {}
        
        # ä»ä¸Šä¸‹æ–‡ä¸­è·å–ç”¨æˆ·æ„å›¾çš„å“ç‰Œ
        user_brand = None
        if context and context.get("intent_result"):
            user_brand = context["intent_result"].get("brand")
        elif context and context.get("filter_history"):
            for filter_item in context["filter_history"]:
                if filter_item.get("type") == "brand":
                    user_brand = filter_item.get("value")
                    break
        
        # å®šä¹‰éœ€è¦æ’é™¤çš„éç³»åˆ—ä»£ç å…³é”®è¯
        excluded_codes = [
            'ECU', 'DCI', 'LNG', 'EDC', 'VEC', 'DOC', 'DCM', 
            'DOCX', 'VECU', 'BCM', 'PDF', 'XLS', 'XLSX', 'PPT', 'PPTX',
            'D31', 'D32', 'D53', 'D56', 'ABS', 'ESP', 'TCS', 'EBD',
            'CAN', 'LIN', 'MOST', 'FLEX', 'KWP', 'UDS', 'OBD'
        ]
        
        for result in results:
            diagram = result.diagram
            file_name = diagram.file_name
            
            # å»é™¤æ–‡ä»¶æ‰©å±•å
            file_name_without_ext = re.sub(r'\.[A-Z]{2,5}$', '', file_name, flags=re.IGNORECASE)
            
            # ç¡®å®šå“ç‰Œ
            brand_in_file = user_brand if user_brand else (diagram.brand or "ä¸œé£")
            
            # ä»æ–‡ä»¶åä¸­æå–ç³»åˆ—ä»£ç 
            if brand_in_file in file_name_without_ext:
                after_brand = file_name_without_ext.split(brand_in_file, 1)[1] if brand_in_file in file_name_without_ext else file_name_without_ext
                # æå–2-3ä¸ªå¤§å†™å­—æ¯ï¼ˆç³»åˆ—ä»£ç ï¼‰
                series_match = re.search(r'([A-Z]{2,3})', after_brand[:30])
                if series_match:
                    potential_code = series_match.group(1)
                    if potential_code not in excluded_codes:
                        display_brand = user_brand if user_brand else (diagram.brand or "ä¸œé£")
                        option_name = f"{display_brand} {potential_code} ç³»åˆ—"
                        option_counts[option_name] = option_counts.get(option_name, 0) + 1
        
        # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶æŒ‰æ•°é‡æ’åº
        options = [
            {"name": name, "count": count}
            for name, count in sorted(option_counts.items(), key=lambda x: x[1], reverse=True)
        ]
        
        return options[:max_options]
    
    def _extract_document_category_options(
        self,
        results: List[ScoredResult],
        max_options: int = 5,
        context: Optional[Dict[str, Any]] = None
    ) -> List[Dict]:
        """
        ä»æœç´¢ç»“æœä¸­æå–æ–‡æ¡£ä¸»é¢˜/ç±»åˆ«é€‰é¡¹
        ä¾‹å¦‚ï¼š"VGTæ‰§è¡Œå™¨"ã€"è§£æ”¾åŠ¨åŠ›(é”¡æŸ´)FAW_52E/91E"ã€"é¾™æ“åŠ¨åŠ›DDI13"ã€"æ¶¡è½®å¢å‹å™¨è½¬é€Ÿä¼ æ„Ÿå™¨"ç­‰
        
        ä½¿ç”¨é…ç½®åŒ–çš„æ¨¡å¼æå–ï¼Œæ”¯æŒé€šè¿‡ category_patterns.json é…ç½®æ–‡ä»¶æ‰©å±•æ¨¡å¼
        
        Args:
            results: æœç´¢ç»“æœåˆ—è¡¨
            max_options: æœ€å¤§é€‰é¡¹æ•°é‡
            context: å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            é€‰é¡¹åˆ—è¡¨ï¼Œæ ¼å¼ï¼š[{"name": "ç±»åˆ«å", "count": æ•°é‡, "ids": [idåˆ—è¡¨]}, ...]
        """
        import re
        from collections import defaultdict
        
        category_to_ids: Dict[str, set] = defaultdict(set)
        
        # ä»é…ç½®æ–‡ä»¶åŠ è½½æ¨¡å¼
        loader = self.pattern_loader
        diagnostic_suffixes = loader.get_diagnostic_suffixes()
        product_intro_keywords = loader.get_product_intro_keywords()
        component_keywords = loader.get_component_keywords()
        brand_list = loader.get_brand_list()
        brand_patterns_config = loader.get_brand_patterns()
        recommended_prefixes = loader.get_recommended_prefixes()
        recommended_stop_markers = loader.get_recommended_stop_markers()
        fallback_config = loader.get_fallback_config()
        validation_config = loader.get_validation_config()
        
        # å®šä¹‰å¸¸è§çš„æ–‡æ¡£ä¸»é¢˜æ¨¡å¼
        # 1. äº§å“/ç³»ç»Ÿåç§°æ¨¡å¼ï¼ˆå¦‚"VGTæ‰§è¡Œå™¨"ã€"æ¶¡è½®å¢å‹å™¨è½¬é€Ÿä¼ æ„Ÿå™¨"ï¼‰
        # 2. å“ç‰Œ+äº§å“æ¨¡å¼ï¼ˆå¦‚"è§£æ”¾åŠ¨åŠ›(é”¡æŸ´)FAW_52E/91E"ã€"é¾™æ“åŠ¨åŠ›DDI13"ï¼‰
        # 3. è¯Šæ–­æŒ‡å¯¼ç±»ï¼ˆå¦‚"VGTæ‰§è¡Œå™¨_è¯Šæ–­æŒ‡å¯¼"ï¼‰
        
        for result in results:
            diagram = result.diagram
            file_name = diagram.file_name or ""
            
            # æå–æ–‡æ¡£ä¸»é¢˜/ç±»åˆ«
            category = None
            
            # æ¨¡å¼1: è¯Šæ–­æŒ‡å¯¼ç±»ï¼ˆå¦‚"VGTæ‰§è¡Œå™¨_è¯Šæ–­æŒ‡å¯¼.DOCX" -> "VGTæ‰§è¡Œå™¨"ï¼‰
            # ä½¿ç”¨é…ç½®åŒ–çš„åç¼€åˆ—è¡¨
            for suffix in diagnostic_suffixes:
                if suffix in file_name:
                    category = file_name.split(suffix)[0].strip()
                    break
            
            # æ¨¡å¼2: äº§å“ä»‹ç»ç±»ï¼ˆå¦‚"é¾™æ“åŠ¨åŠ›DDI13äº§å“ä»‹ç»ã€5ã€‘-VGT.DOCX" -> "é¾™æ“åŠ¨åŠ›DDI13"ï¼‰
            if not category:
                for keyword in product_intro_keywords:
                    if keyword in file_name:
                        # æå–"äº§å“ä»‹ç»"å‰é¢çš„éƒ¨åˆ†
                        parts = file_name.split(keyword)
                        if parts:
                            category = parts[0].strip()
                            # æ¸…ç†å¸¸è§çš„åç¼€ï¼ˆä»é…ç½®ä¸­è·å–ï¼‰
                            product_intro_pattern = loader.get_patterns().get("product_intro", {})
                            cleanup_patterns = product_intro_pattern.get("cleanup_patterns", [r'ã€\d+ã€‘', r'[-_]'])
                            for pattern in cleanup_patterns:
                                category = re.sub(pattern, '', category).strip()
                        break
            
            # æ¨¡å¼3: ã€æ¨èã€‘å“ç‰Œ+äº§å“æ¨¡å¼ï¼ˆå¦‚"ã€æ¨èã€‘è§£æ”¾åŠ¨åŠ›(é”¡æŸ´)FAW_52E/91E ã€VGT/VNT_...ã€‘" -> "ã€æ¨èã€‘è§£æ”¾åŠ¨åŠ›(é”¡æŸ´)FAW_52E/91E"ï¼‰
            if not category:
                for prefix in recommended_prefixes:
                    if prefix in file_name:
                        # æå–"ã€æ¨èã€‘"åé¢çš„éƒ¨åˆ†ï¼Œç›´åˆ°é‡åˆ°åœæ­¢æ ‡è®°æˆ–æ–‡ä»¶æ‰©å±•å
                        after_prefix = file_name.split(prefix, 1)[1]
                        # æå–åˆ°åœæ­¢æ ‡è®°ä¹‹å‰ï¼ˆä¿ç•™å‰ç¼€ï¼Œå› ä¸ºè¿™æ˜¯é‡è¦çš„æ ‡è¯†ï¼‰
                        stop_pattern = '|'.join(re.escape(marker) for marker in recommended_stop_markers)
                        match = re.match(rf'^([^{stop_pattern}]+?)(?:{stop_pattern}|\.)', after_prefix)
                        if match:
                            category = prefix + match.group(1).strip()
                        else:
                            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åœæ­¢æ ‡è®°ï¼Œæå–åˆ°æ–‡ä»¶æ‰©å±•åä¹‹å‰
                            category_name = re.sub(r'\.[A-Z]{2,5}$', '', after_prefix, flags=re.IGNORECASE).strip()
                            # å¦‚æœæå–çš„åç§°å¤ªé•¿ï¼Œå°è¯•åœ¨ç¬¬ä¸€ä¸ªåœæ­¢æ ‡è®°å¤„æˆªæ–­
                            for marker in recommended_stop_markers:
                                if marker in category_name:
                                    category = prefix + category_name.split(marker)[0].strip()
                                    break
                            if not category:
                                category = prefix + category_name
                        break
            
            # æ¨¡å¼4: ä¼ æ„Ÿå™¨/æ‰§è¡Œå™¨ç±»ï¼ˆå¦‚"æ¶¡è½®å¢å‹å™¨è½¬é€Ÿä¼ æ„Ÿå™¨_è¯Šæ–­æŒ‡å¯¼.DOCX" -> "æ¶¡è½®å¢å‹å™¨è½¬é€Ÿä¼ æ„Ÿå™¨"ï¼‰
            # ä½¿ç”¨é…ç½®åŒ–çš„å…³é”®è¯åˆ—è¡¨
            if not category:
                component_pattern = loader.get_patterns().get("component_keywords", {})
                max_length_after = component_pattern.get("max_length_after_keyword", 10)
                for keyword in component_keywords:
                    if keyword in file_name:
                        # æ‰¾åˆ°å…³é”®è¯çš„ä½ç½®ï¼Œæå–å‰é¢çš„éƒ¨åˆ†
                        idx = file_name.find(keyword)
                        if idx != -1:
                            # æå–ä»å¼€å¤´åˆ°å…³é”®è¯+å…³é”®è¯åçš„éƒ¨åˆ†
                            end_pos = min(idx + len(keyword) + max_length_after, len(file_name))
                            potential = file_name[:end_pos]
                            # æ¸…ç†ä¸‹åˆ’çº¿å’Œæ–‡ä»¶æ‰©å±•å
                            potential = re.sub(r'_[^_]*$', '', potential)
                            potential = re.sub(r'\.[A-Z]{2,5}$', '', potential, flags=re.IGNORECASE)
                            if len(potential) > 3:  # ç¡®ä¿æå–åˆ°çš„ç±»åˆ«æœ‰æ„ä¹‰
                                category = potential.strip()
                                break
            
            # æ¨¡å¼5: å“ç‰Œ+ç³»åˆ—æ¨¡å¼ï¼ˆå¦‚"è§£æ”¾åŠ¨åŠ›(é”¡æŸ´)FAW_52E/91E"ã€"æŸ³æ±½ä¹˜é¾™H7"ã€"ä¸œé£æŸ³æ±½ä¹˜é¾™H7"ï¼‰
            # ä½¿ç”¨é…ç½®åŒ–çš„å“ç‰Œåˆ—è¡¨å’Œæ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
            if not category:
                if any(brand in file_name for brand in brand_list):
                    # ä½¿ç”¨é…ç½®ä¸­çš„å“ç‰Œæ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
                    for pattern_config in brand_patterns_config:
                        pattern_regex = pattern_config.get("regex")
                        if pattern_regex:
                            match = re.search(pattern_regex, file_name)
                            if match:
                                category = match.group(0).strip()
                                # æ¸…ç†æ–‡ä»¶æ‰©å±•å
                                category = re.sub(r'\.[A-Z]{2,5}$', '', category, flags=re.IGNORECASE)
                                
                                # åº”ç”¨åå¤„ç†è§„åˆ™
                                post_processing = pattern_config.get("post_processing", [])
                                for post_proc in post_processing:
                                    condition = post_proc.get("condition")
                                    condition_value = post_proc.get("value")
                                    post_regex = post_proc.get("regex")
                                    
                                    if condition == "contains" and condition_value and post_regex:
                                        if condition_value in category:
                                            match_h = re.match(post_regex, category)
                                            if match_h:
                                                category = match_h.group(1)
                                
                                # åº”ç”¨é€šç”¨æ¸…ç†è§„åˆ™
                                common_cleanup = loader.get_patterns().get("brand_patterns", {}).get("common_cleanup", [])
                                for cleanup_pattern in common_cleanup:
                                    category = re.sub(cleanup_pattern, '', category)
                                
                                break
            
            # å¦‚æœè¿˜æ²¡æœ‰æå–åˆ°ç±»åˆ«ï¼Œä½¿ç”¨é€šç”¨æå–æœºåˆ¶ï¼ˆfallbackï¼‰
            if not category:
                # å»é™¤æ–‡ä»¶æ‰©å±•å
                name_without_ext = re.sub(r'\.[A-Z]{2,5}$', '', file_name, flags=re.IGNORECASE)
                max_length = fallback_config.get("max_length", 30)
                separators = fallback_config.get("separators", ["ã€", "(", "_", "-"])
                cleanup_patterns = fallback_config.get("cleanup_patterns", [r'[-_]\d+$', r'[-_]è¯Šæ–­æŒ‡å¯¼$'])
                
                # æå–å‰Nä¸ªå­—ç¬¦ä½œä¸ºç±»åˆ«ï¼ˆå¦‚æœæ–‡ä»¶åè¾ƒé•¿ï¼‰
                if len(name_without_ext) > max_length:
                    # å°è¯•åœ¨åˆé€‚çš„ä½ç½®æˆªæ–­ï¼ˆä¼˜å…ˆåœ¨åˆ†éš”ç¬¦å¤„æˆªæ–­ï¼‰
                    for sep in separators:
                        if sep in name_without_ext[:max_length]:
                            category = name_without_ext.split(sep)[0].strip()
                            break
                    if not category:
                        category = name_without_ext[:max_length].strip()
                else:
                    # å¦‚æœæ–‡ä»¶åè¾ƒçŸ­ï¼Œç›´æ¥ä½¿ç”¨ï¼ˆä½†è¦å»é™¤å¸¸è§çš„åç¼€ï¼‰
                    category = name_without_ext
                    # å»é™¤å¸¸è§çš„åç¼€æ¨¡å¼
                    for cleanup_pattern in cleanup_patterns:
                        category = re.sub(cleanup_pattern, '', category)
            
            # æ¸…ç†å’Œè§„èŒƒåŒ–ç±»åˆ«åç§°ï¼ˆä½¿ç”¨é…ç½®åŒ–çš„éªŒè¯è§„åˆ™ï¼‰
            if category:
                # å»é™¤å¤šä½™çš„ç©ºæ ¼ï¼ˆå¦‚æœé…ç½®è¦æ±‚ï¼‰
                if validation_config.get("remove_spaces", True):
                    category = re.sub(r'\s+', '', category)
                
                # å»é™¤æŒ‡å®šçš„å­—ç¬¦
                strip_chars = validation_config.get("strip_chars", "ã€ã€‘()ï¼ˆï¼‰-_")
                category = category.strip(strip_chars)
                
                # éªŒè¯é•¿åº¦
                min_length = validation_config.get("min_length", 2)
                max_length = validation_config.get("max_length", 50)
                if min_length <= len(category) <= max_length:
                    category_to_ids[category].add(diagram.id)
        
        # è½¬æ¢ä¸ºé€‰é¡¹åˆ—è¡¨
        options = []
        for category, ids in category_to_ids.items():
            if len(ids) > 0:  # ç¡®ä¿è‡³å°‘æœ‰ä¸€ä¸ªç»“æœ
                options.append({
                    "name": category,
                    "count": len(ids),
                    "ids": sorted(ids)
                })
        
        # æŒ‰æ•°é‡é™åºæ’åº
        options.sort(key=lambda x: x["count"], reverse=True)
        
        # å¦‚æœç±»åˆ«å¤ªå¤šï¼Œå°è¯•åˆå¹¶ç›¸ä¼¼çš„ç±»åˆ«
        if len(options) > max_options * 2:
            # åˆå¹¶ç›¸ä¼¼çš„ç±»åˆ«ï¼ˆä¾‹å¦‚éƒ½åŒ…å«"VGT"çš„ç±»åˆ«ï¼‰
            merged_options = {}
            for opt in options:
                name = opt["name"]
                merged = False
                for existing_name in list(merged_options.keys()):
                    # æ£€æŸ¥æ˜¯å¦æœ‰ç›¸ä¼¼æ€§ï¼ˆåŒ…å«ç›¸åŒçš„å…³é”®è¯ï¼‰
                    # æå–å…³é”®è¯ï¼ˆå»é™¤å¸¸è§è¯ï¼‰
                    name_keywords = set(re.findall(r'[A-Z]{2,}|[\u4e00-\u9fa5]{2,}', name))
                    existing_keywords = set(re.findall(r'[A-Z]{2,}|[\u4e00-\u9fa5]{2,}', existing_name))
                    # å¦‚æœæœ‰è¶…è¿‡50%çš„å…³é”®è¯é‡å ï¼Œåˆå¹¶
                    if name_keywords and existing_keywords:
                        overlap = len(name_keywords & existing_keywords) / len(name_keywords | existing_keywords)
                        if overlap > 0.5:
                            # åˆå¹¶åˆ°æ›´é•¿çš„åç§°
                            if len(name) > len(existing_name):
                                merged_options[name] = merged_options.pop(existing_name)
                                merged_options[name]["ids"].update(opt["ids"])
                                merged_options[name]["count"] = len(merged_options[name]["ids"])
                            else:
                                merged_options[existing_name]["ids"].update(opt["ids"])
                                merged_options[existing_name]["count"] = len(merged_options[existing_name]["ids"])
                            merged = True
                            break
                if not merged:
                    merged_options[name] = {"name": name, "ids": set(opt["ids"]), "count": opt["count"]}
            
            # è½¬æ¢å›åˆ—è¡¨æ ¼å¼
            options = []
            for name, data in merged_options.items():
                options.append({
                    "name": name,
                    "count": data["count"],
                    "ids": sorted(data["ids"]) if isinstance(data["ids"], set) else data["ids"]
                })
            options.sort(key=lambda x: x["count"], reverse=True)
        
        return options[:max_options * 2]  # è¿”å›æ›´å¤šé€‰é¡¹ï¼Œè®©_finalize_options_with_idså¤„ç†æˆªæ–­
    
    def _merge_filename_prefixes(
        self,
        results: List[ScoredResult],
        options: List[Dict],
        max_options: int = 5
    ) -> Optional[List[Dict]]:
        """
        åˆå¹¶æ–‡ä»¶åå‰ç¼€ï¼Œå‡å°‘é€‰é¡¹æ•°é‡
        ä»å·¦åˆ°å³åŒ¹é…ç›¸åŒçš„å‰ç¼€éƒ¨åˆ†ï¼Œå°†ç›¸ä¼¼çš„æ–‡ä»¶ååˆå¹¶
        
        ä¾‹å¦‚ï¼š
        - "æŸ³æ±½ä¹˜é¾™H7..." (3ä¸ªç»“æœ)
        - "æŸ³æ±½_ä¹˜é¾™H72D..." (1ä¸ªç»“æœ)
        - "æŸ³æ±½_ä¹˜é¾™H72S..." (1ä¸ªç»“æœ)
        å¯ä»¥åˆå¹¶ä¸º "æŸ³æ±½ä¹˜é¾™H7" ç³»åˆ— (5ä¸ªç»“æœ)
        
        Args:
            results: æœç´¢ç»“æœåˆ—è¡¨
            options: é€‰é¡¹åˆ—è¡¨ï¼ˆæ ¼å¼ï¼š[{"name": "æ–‡ä»¶å", "count": æ•°é‡, "ids": [idåˆ—è¡¨]}, ...]ï¼‰
            max_options: æœ€å¤§é€‰é¡¹æ•°é‡
            
        Returns:
            åˆå¹¶åçš„é€‰é¡¹åˆ—è¡¨ï¼Œå¦‚æœæ— æ³•åˆå¹¶åˆ™è¿”å›None
        """
        import re
        from collections import defaultdict
        
        print(f"ğŸ” _merge_filename_prefixes è¢«è°ƒç”¨: optionsæ•°é‡={len(options) if options else 0}")
        if not options or len(options) < 10:
            print(f"âš ï¸ é€‰é¡¹æ•°é‡ä¸è¶³10ï¼Œè·³è¿‡åˆå¹¶: {len(options) if options else 0}")
            return None
        
        # è·å–æ‰€æœ‰æ–‡ä»¶åå’Œå¯¹åº”çš„ids
        name_to_ids = {}
        name_to_count = {}
        for option in options:
            name = option.get("name", "")
            if name:
                ids = option.get("ids", [])
                if ids:
                    name_to_ids[name] = set(ids)
                    name_to_count[name] = len(ids)
                else:
                    # å¦‚æœæ²¡æœ‰idsï¼Œä»resultsä¸­æŸ¥æ‰¾
                    count = option.get("count", 0)
                    for result in results:
                        if result.diagram.file_name == name:
                            name_to_ids.setdefault(name, set()).add(result.diagram.id)
                            name_to_count[name] = count or 1
        
        file_names = list(name_to_ids.keys())
        if not file_names:
            return None
        
        # å»é™¤æ–‡ä»¶æ‰©å±•å
        def remove_ext(name: str) -> str:
            return re.sub(r'\.[A-Z]{2,5}$', '', name, flags=re.IGNORECASE)
        
        # è§„èŒƒåŒ–æ–‡ä»¶åç”¨äºå‰ç¼€æ¯”è¾ƒï¼ˆå»é™¤åˆ†éš”ç¬¦ï¼Œä½†ä¿ç•™å­—ç¬¦é¡ºåºï¼‰
        def normalize_for_comparison(name: str) -> str:
            name = remove_ext(name)
            # å°†ä¸‹åˆ’çº¿ã€è¿å­—ç¬¦ã€ç©ºæ ¼ç­‰ç»Ÿä¸€å»é™¤ï¼Œä½†ä¿ç•™å­—ç¬¦é¡ºåº
            name = re.sub(r'[_\-\s]+', '', name)
            return name
        
        # ä»å·¦åˆ°å³æŸ¥æ‰¾å…¬å…±å‰ç¼€ï¼ˆåŸºäºè§„èŒƒåŒ–åçš„åç§°ï¼‰
        def find_common_prefix_normalized(names: List[str], min_length: int = 3) -> Optional[str]:
            if not names:
                return None
            
            normalized = [normalize_for_comparison(n) for n in names]
            if not normalized:
                return None
            
            # æ‰¾åˆ°æœ€çŸ­çš„åç§°ä½œä¸ºåŸºå‡†
            shortest = min(normalized, key=len)
            if len(shortest) < min_length:
                return None
            
            # ä»å·¦åˆ°å³æŸ¥æ‰¾å…¬å…±å‰ç¼€é•¿åº¦
            prefix_len = 0
            for i in range(len(shortest)):
                char = shortest[i]
                if all(n[i] == char for n in normalized if i < len(n)):
                    prefix_len = i + 1
                else:
                    break
            
            if prefix_len < min_length:
                return None
            
            # å¯¹äºä¸­æ–‡+å­—æ¯+æ•°å­—çš„ç»„åˆï¼ˆå¦‚"æŸ³æ±½ä¹˜é¾™H7"ï¼‰ï¼Œç¡®ä¿è‡³å°‘åŒ…å«ä¸€ä¸ªå®Œæ•´çš„è¯
            # æ£€æŸ¥å‰ç¼€æ˜¯å¦åŒ…å«è‡³å°‘ä¸€ä¸ªä¸­æ–‡å­—ç¬¦
            prefix_chars = shortest[:prefix_len]
            has_chinese = any('\u4e00' <= c <= '\u9fff' for c in prefix_chars)
            if not has_chinese and prefix_len < 5:
                # å¦‚æœæ²¡æœ‰ä¸­æ–‡å­—ç¬¦ä¸”é•¿åº¦è¾ƒçŸ­ï¼Œå¯èƒ½éœ€è¦æ›´é•¿çš„å‰ç¼€
                return None
            
            # å°†è§„èŒƒåŒ–åçš„å‰ç¼€æ˜ å°„å›åŸå§‹åç§°
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªåç§°ï¼Œæ‰¾åˆ°å¯¹åº”é•¿åº¦çš„å‰ç¼€
            original_name = names[0]
            normalized_first = normalize_for_comparison(original_name)
            
            # è®¡ç®—åŸå§‹åç§°ä¸­å¯¹åº”çš„å‰ç¼€ä½ç½®
            # ç”±äºè§„èŒƒåŒ–å»é™¤äº†åˆ†éš”ç¬¦ï¼Œéœ€è¦æ‰¾åˆ°åŸå§‹åç§°ä¸­å¯¹åº”å­—ç¬¦çš„ä½ç½®
            char_count = 0
            prefix_end = 0
            for i, char in enumerate(original_name):
                if char not in '_- \t\n\r':
                    char_count += 1
                    if char_count >= prefix_len:
                        prefix_end = i + 1
                        break
            
            if prefix_end == 0:
                return None
            
            prefix = original_name[:prefix_end]
            # å°è¯•åœ¨åˆé€‚çš„ä½ç½®æˆªæ–­ï¼ˆä¼˜å…ˆåœ¨åˆ†éš”ç¬¦å¤„ï¼Œä½†ä¸è¦æˆªæ–­å¤ªçŸ­ï¼‰
            for sep in ["_", "-", " ", "ã€", "("]:
                sep_pos = prefix.rfind(sep)
                if sep_pos >= min_length // 2:  # ç¡®ä¿å‰ç¼€ä¸ä¼šå¤ªçŸ­
                    prefix = prefix[:sep_pos + len(sep)]
                    break
            
            return prefix.rstrip('_ -ã€ï¼ˆ')
        
        # åˆ†ç»„ç­–ç•¥ï¼šæŒ‰å‰ç¼€åˆ†ç»„
        merged_groups: Dict[str, List[str]] = defaultdict(list)
        remaining_names = set(file_names)
        
        # æŒ‰è§„èŒƒåŒ–åçš„é•¿åº¦æ’åºï¼Œä»é•¿åˆ°çŸ­å¤„ç†
        sorted_names = sorted(file_names, key=lambda x: len(normalize_for_comparison(x)), reverse=True)
        
        processed = set()
        for name in sorted_names:
            if name in processed:
                continue
            
            # æŸ¥æ‰¾å¯ä»¥ä¸æ­¤åç§°åˆå¹¶çš„å…¶ä»–åç§°
            candidates = [name]
            
            # æŸ¥æ‰¾å…¶ä»–å¯ä»¥åˆå¹¶çš„åç§°
            for other_name in remaining_names:
                if other_name == name or other_name in processed:
                    continue
                
                # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿé•¿çš„å…¬å…±å‰ç¼€
                common_prefix = find_common_prefix_normalized([name, other_name], min_length=3)
                if common_prefix:
                    # æ£€æŸ¥è§„èŒƒåŒ–åçš„åç§°æ˜¯å¦å…±äº«è¶³å¤Ÿé•¿çš„å‰ç¼€
                    norm_name = normalize_for_comparison(name)
                    norm_other = normalize_for_comparison(other_name)
                    min_len = min(len(norm_name), len(norm_other))
                    if min_len >= 3:
                        # æ£€æŸ¥å‰3ä¸ªå­—ç¬¦æ˜¯å¦ç›¸åŒï¼ˆé™ä½è¦æ±‚ï¼Œä»¥ä¾¿æ›´å¥½åœ°åˆå¹¶ï¼‰
                        if norm_name[:min(3, len(norm_name))] == norm_other[:min(3, len(norm_other))]:
                            candidates.append(other_name)
            
            # å¦‚æœæ‰¾åˆ°å¤šä¸ªå¯ä»¥åˆå¹¶çš„åç§°
            if len(candidates) > 1:
                # æ‰¾åˆ°è¿™äº›åç§°çš„å…¬å…±å‰ç¼€
                common_prefix = find_common_prefix_normalized(candidates, min_length=3)
                if common_prefix and len(common_prefix) >= 3:
                    group_key = common_prefix + "ç³»åˆ—"
                    merged_groups[group_key].extend(candidates)
                    processed.update(candidates)
                    remaining_names -= set(candidates)
            else:
                processed.add(name)
        
        # å¦‚æœæˆåŠŸåˆå¹¶äº†ä¸€äº›åç§°ï¼Œåˆ›å»ºæ–°çš„é€‰é¡¹åˆ—è¡¨
        if merged_groups:
            merged_options = []
            
            # æ·»åŠ åˆå¹¶åçš„åˆ†ç»„
            for group_name, names_in_group in merged_groups.items():
                all_ids = set()
                total_count = 0
                for name in names_in_group:
                    ids = name_to_ids.get(name, set())
                    all_ids.update(ids)
                    total_count += name_to_count.get(name, len(ids))
                
                if all_ids:
                    merged_options.append({
                        "name": group_name,
                        "count": len(all_ids),
                        "ids": sorted(all_ids)
                    })
            
            # æ·»åŠ æœªåˆå¹¶çš„å•ç‹¬åç§°
            for name in remaining_names:
                ids = name_to_ids.get(name, set())
                count = name_to_count.get(name, len(ids))
                if ids:
                    merged_options.append({
                        "name": remove_ext(name),
                        "count": count,
                        "ids": sorted(ids)
                    })
            
            # æŒ‰æ•°é‡é™åºæ’åº
            merged_options.sort(key=lambda x: x["count"], reverse=True)
            
            # å¦‚æœåˆå¹¶åé€‰é¡¹æ•°é‡å‡å°‘ä¸”>=2ï¼Œè¿”å›åˆå¹¶åçš„é€‰é¡¹
            if len(merged_options) < len(options) and len(merged_options) >= 2:
                return merged_options[:max_options * 2]  # è¿”å›æ›´å¤šé€‰é¡¹ï¼Œè®©_finalize_options_with_idså¤„ç†
        
        return None
    
    def _extract_type_variants(
        self,
        results: List[ScoredResult],
        max_options: int = 5,
        context: Optional[Dict[str, Any]] = None
    ) -> List[Dict]:
        """
        æå–ç±»å‹å˜ä½“é€‰é¡¹ï¼ˆç”¨äºå½“ç”¨æˆ·å·²ç»æŒ‡å®šäº†ç±»å‹æ—¶ï¼‰
        ä¾‹å¦‚ï¼šå¦‚æœç”¨æˆ·å·²ç»æŒ‡å®šäº†"ä»ªè¡¨å›¾"ï¼Œæå–"ECUä»ªè¡¨é’ˆè„šå›¾"ã€"æ•´è½¦ä»ªè¡¨çº¿è·¯å›¾"ç­‰
        
        Args:
            results: æœç´¢ç»“æœåˆ—è¡¨
            max_options: æœ€å¤§é€‰é¡¹æ•°é‡
            context: å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            é€‰é¡¹åˆ—è¡¨
        """
        from backend.app.utils.hierarchy_util import HierarchyUtil
        
        diagrams = [result.diagram for result in results]
        option_counts = {}
        
        # ä»ä¸Šä¸‹æ–‡ä¸­è·å–ç”¨æˆ·å·²æŒ‡å®šçš„ç±»å‹å…³é”®è¯
        type_keywords = []
        if context and context.get("filter_history"):
            for filter_item in context["filter_history"]:
                if filter_item.get("type") == "type":
                    type_keywords.append(filter_item.get("value", ""))
        
        # å¦‚æœæ²¡æœ‰ä»ç­›é€‰å†å²ä¸­è·å–ï¼Œå°è¯•ä»å½“å‰æŸ¥è¯¢ä¸­æå–
        if not type_keywords and context and context.get("current_query"):
            query = context["current_query"]
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ç±»å‹å…³é”®è¯
            type_patterns = ["ä»ªè¡¨", "ECU", "æ•´è½¦", "çº¿è·¯", "é’ˆè„š"]
            for pattern in type_patterns:
                if pattern in query:
                    type_keywords.append(pattern)
                    break
        
        # ä»å±‚çº§è·¯å¾„å’Œæ–‡ä»¶åç§°ä¸­æå–åŒ…å«ç±»å‹å…³é”®è¯çš„å…·ä½“ç±»å‹å˜ä½“
        for diagram in diagrams:
            # æ£€æŸ¥å±‚çº§è·¯å¾„ä¸­çš„ç±»å‹ä¿¡æ¯
            for level in diagram.hierarchy_path:
                level_lower = level.lower()
                # å¦‚æœå±‚çº§åŒ…å«ç±»å‹å…³é”®è¯ï¼Œä¸”ä¸æ˜¯ç®€å•çš„ç±»å‹åç§°ï¼Œæå–ä½œä¸ºé€‰é¡¹
                if any(keyword in level_lower for keyword in type_keywords) if type_keywords else True:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯å…·ä½“çš„ç±»å‹å˜ä½“ï¼ˆåŒ…å«å¤šä¸ªå…³é”®è¯æˆ–æ›´è¯¦ç»†çš„æè¿°ï¼‰
                    if len(level) > 5:  # é¿å…æå–å¤ªçŸ­çš„å±‚çº§
                        # æ¸…ç†å±‚çº§å€¼
                        level_clean = level.replace('*', '').strip()
                        if level_clean and level_clean not in ["ç”µè·¯å›¾", "ä»ªè¡¨å›¾", "ECUå›¾"]:
                            option_counts[level_clean] = option_counts.get(level_clean, 0) + 1
            
            # æ£€æŸ¥æ–‡ä»¶åç§°ä¸­çš„ç±»å‹ä¿¡æ¯
            file_name = diagram.file_name
            if any(keyword in file_name.lower() for keyword in type_keywords) if type_keywords else True:
                # å°è¯•ä»æ–‡ä»¶åç§°ä¸­æå–ç±»å‹ç›¸å…³ä¿¡æ¯
                # è¿™é‡Œå¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–ï¼Œæå–æ–‡ä»¶åç§°ä¸­åŒ…å«ç±»å‹å…³é”®è¯çš„éƒ¨åˆ†
                pass
        
        # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶æŒ‰æ•°é‡æ’åº
        options = [
            {"name": name, "count": count}
            for name, count in option_counts.items()
        ]
        options.sort(key=lambda x: x["count"], reverse=True)
        
        return options[:max_options]
    
    def optimize_options(
        self,
        options: List[Dict],
        max_options: int = 5
    ) -> List[Dict]:
        """
        ä¼˜åŒ–é€‰é¡¹åˆ—è¡¨ï¼ˆå»é‡ã€æ’åºï¼‰
        
        Args:
            options: é€‰é¡¹åˆ—è¡¨ï¼Œæ ¼å¼ï¼š[{"name": "é€‰é¡¹å", "count": æ•°é‡}, ...]
            max_options: æœ€å¤§é€‰é¡¹æ•°é‡
            
        Returns:
            ä¼˜åŒ–åçš„é€‰é¡¹åˆ—è¡¨
        """
        if not options:
            return []
        
        # å»é‡ï¼šåˆå¹¶ç›¸ä¼¼é€‰é¡¹ï¼ˆå…ˆåšè½»åº¦è§„èŒƒåŒ–ï¼Œé¿å…å› ä¸ºç©ºæ ¼/é‡å¤â€œç³»åˆ—â€å¯¼è‡´ A/B çœ‹èµ·æ¥ä¸€æ ·ï¼‰
        def norm_name(s: str) -> str:
            if not s:
                return ""
            s = str(s).strip()
            s = re.sub(r"\s+", " ", s)
            s = s.replace("  ", " ")
            # collapse duplicated â€œç³»åˆ—â€
            s = re.sub(r"(ç³»åˆ—)\s*(ç³»åˆ—)+", r"\1", s)
            return s.strip()

        merged_options = {}
        for option in options:
            name = norm_name(option['name'])
            count = option['count']
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ç›¸ä¼¼çš„é€‰é¡¹ï¼ˆåŒ…å«å…³ç³»ï¼‰
            merged = False
            for existing_name in list(merged_options.keys()):
                # å¦‚æœæ–°é€‰é¡¹åŒ…å«ç°æœ‰é€‰é¡¹ï¼Œåˆå¹¶ï¼ˆä¿ç•™æ›´å…·ä½“çš„ï¼‰
                if name in existing_name:
                    # æ–°é€‰é¡¹æ˜¯ç°æœ‰é€‰é¡¹çš„ä¸€éƒ¨åˆ†ï¼Œä¸åˆå¹¶
                    pass
                elif existing_name in name:
                    # ç°æœ‰é€‰é¡¹æ˜¯æ–°é€‰é¡¹çš„ä¸€éƒ¨åˆ†ï¼Œç”¨æ–°é€‰é¡¹æ›¿æ¢
                    merged_options[name] = merged_options.pop(existing_name) + count
                    merged = True
                    break
            
            if not merged:
                if name in merged_options:
                    merged_options[name] += count
                else:
                    merged_options[name] = count
        
        # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶æŒ‰æ•°é‡æ’åº
        optimized = [
            {"name": name, "count": count}
            for name, count in merged_options.items()
        ]
        optimized.sort(key=lambda x: x["count"], reverse=True)
        
        # é™åˆ¶é€‰é¡¹æ•°é‡
        return optimized[:max_options]
    
    def _generate_question_text(
        self,
        option_type: str,
        total_count: int,
        context: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        ç”Ÿæˆé—®é¢˜æ–‡æœ¬ï¼ˆé»˜è®¤æ¨¡æ¿ï¼‰
        
        æŒ‰ç…§é¡¹ç›®æ–‡æ¡£ç¤ºä¾‹æ ¼å¼ï¼š
        - ç¬¬ä¸€æ¬¡æé—®ï¼š"æˆ‘æ‰¾åˆ°äº†XXç›¸å…³çš„ç”µè·¯å›¾ã€‚è¯·é—®æ‚¨éœ€è¦çš„æ˜¯ï¼š"
        - ç¬¬äºŒæ¬¡æé—®ï¼š"æ˜ç™½äº†ã€‚è¯·é—®æ‚¨éœ€è¦çš„æ˜¯å“ªç§ç±»å‹çš„ä»ªè¡¨ç”µè·¯å›¾ï¼š"
        
        Args:
            option_type: é€‰é¡¹ç±»å‹
            total_count: æ€»ç»“æœæ•°
            context: å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            é—®é¢˜æ–‡æœ¬
        """
        # æ£€æŸ¥æ˜¯å¦æœ‰ç­›é€‰å†å²
        has_filter_history = context and context.get("filter_history")
        current_query = context.get("current_query", "") if context else ""
        
        # å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡æé—®ï¼ˆæ²¡æœ‰ç­›é€‰å†å²ï¼‰
        if not has_filter_history:
            # ä»å½“å‰æŸ¥è¯¢ä¸­æå–å“ç‰Œä¿¡æ¯
            if option_type in ("variant", "brand_model"):
                # å°è¯•ä»æŸ¥è¯¢ä¸­æå–å“ç‰Œ
                brand_keywords = ["ä¸œé£", "è§£æ”¾", "é‡æ±½", "ä¸‰ä¸€", "å¾å·¥", "ç¦ç”°", "çº¢å²©"]
                brand = None
                for keyword in brand_keywords:
                    if keyword in current_query:
                        brand = keyword
                        break
                
                if brand:
                    return f"æˆ‘æ‰¾åˆ°äº†{brand}ç›¸å…³çš„ç”µè·¯å›¾ã€‚è¯·é—®æ‚¨éœ€è¦çš„æ˜¯ï¼š"
                else:
                    return f"æˆ‘æ‰¾åˆ°äº†ç›¸å…³ç”µè·¯å›¾ã€‚è¯·é—®æ‚¨éœ€è¦çš„æ˜¯ï¼š"
            elif option_type == "brand":
                return f"æˆ‘æ‰¾åˆ°äº†ç›¸å…³ç”µè·¯å›¾ã€‚è¯·é—®æ‚¨éœ€è¦çš„æ˜¯ï¼š"
            else:
                return f"æˆ‘æ‰¾åˆ°äº†ç›¸å…³ç”µè·¯å›¾ã€‚è¯·é—®æ‚¨éœ€è¦çš„æ˜¯ï¼š"
        
        # å¦‚æœæœ‰ç­›é€‰å†å²ï¼Œè¯´æ˜æ˜¯åç»­æé—®
        filters = context.get("filter_history", [])
        if filters:
            last_filter = filters[-1]
            filter_value = last_filter.get("value", "")
            
            if option_type in ("variant", "brand_model"):
                return f"æˆ‘æ‰¾åˆ°äº†{filter_value}ç›¸å…³çš„ç”µè·¯å›¾ã€‚è¯·é—®æ‚¨éœ€è¦çš„æ˜¯ï¼š"
            elif option_type == "model":
                return f"æ˜ç™½äº†ã€‚è¯·é—®æ‚¨éœ€è¦çš„æ˜¯å“ªç§å‹å·ï¼š"
            elif option_type == "type":
                return f"æ˜ç™½äº†ã€‚è¯·é—®æ‚¨éœ€è¦çš„æ˜¯å“ªç§ç±»å‹çš„ä»ªè¡¨ç”µè·¯å›¾ï¼š"
            elif option_type == "document_category":
                return f"æ˜ç™½äº†ã€‚è¯·é—®æ‚¨éœ€è¦çš„æ˜¯å“ªä¸€ä»½èµ„æ–™ï¼š"
            else:
                return f"æ˜ç™½äº†ã€‚è¯·é€‰æ‹©æ‚¨éœ€è¦çš„é€‰é¡¹ï¼š"
        
        # æ–‡æ¡£ä¸»é¢˜åˆ†ç±»çš„é»˜è®¤é—®é¢˜æ–‡æœ¬
        if option_type == "document_category":
            return f"æ˜ç™½äº†ã€‚è¯·é—®æ‚¨éœ€è¦çš„æ˜¯å“ªä¸€ä»½èµ„æ–™ï¼š"
        
        # æ–‡ä»¶åå‰ç¼€åˆå¹¶çš„é—®é¢˜æ–‡æœ¬
        if option_type == "filename_prefix":
            return f"æ˜ç™½äº†ã€‚è¯·é—®æ‚¨éœ€è¦çš„æ˜¯å“ªä¸€ä»½èµ„æ–™ï¼š"
        
        return f"æˆ‘æ‰¾åˆ°äº†ç›¸å…³ç”µè·¯å›¾ã€‚è¯·é—®æ‚¨éœ€è¦çš„æ˜¯ï¼š"
    
    def format_question_message(self, question_data: Dict) -> str:
        """
        æ ¼å¼åŒ–é—®é¢˜æ¶ˆæ¯ï¼ˆç”¨äºæ˜¾ç¤ºç»™ç”¨æˆ·ï¼‰
        
        æŒ‰ç…§é¡¹ç›®æ–‡æ¡£ç¤ºä¾‹æ ¼å¼ï¼š
        - é€‰é¡¹æ ¼å¼ï¼šA. ä¸œé£å¤©é¾™ KL ç³»åˆ—ï¼ˆè€Œä¸æ˜¯ A. ä¸œé£ DOC (4ä¸ªç»“æœ)ï¼‰
        
        Args:
            question_data: é—®é¢˜æ•°æ®ï¼ˆç”±generate_questionè¿”å›ï¼‰
            
        Returns:
            æ ¼å¼åŒ–çš„æ¶ˆæ¯æ–‡æœ¬
        """
        message = f"{question_data['question']}\n"
        
        for option in question_data['options']:
            # æ ¼å¼åŒ–é€‰é¡¹åç§°ï¼Œæ·»åŠ "ç³»åˆ—"åç¼€ï¼ˆå¦‚æœæ˜¯å“ç‰Œ+å‹å·ç»„åˆï¼‰
            option_name = option['name']
            option_type = question_data.get('option_type', '')
            
            # å¦‚æœæ˜¯å“ç‰Œ+å‹å·ç»„åˆï¼Œæ·»åŠ "ç³»åˆ—"åç¼€
            if option_type == "brand_model" and "ç³»åˆ—" not in option_name:
                option_name = f"{option_name} ç³»åˆ—"
            # å¦‚æœæ˜¯ç±»å‹é€‰æ‹©ï¼Œä¿æŒåŸæ ·æˆ–æ·»åŠ æè¿°
            elif option_type == "type":
                # ä¿æŒåŸæ ·ï¼ŒLLMåº”è¯¥å·²ç»ç”Ÿæˆäº†åˆé€‚çš„æè¿°
                pass
            
            message += f"{option['label']}. {option_name}\n"
        
        return message
    
    def parse_user_choice(
        self,
        user_input: str,
        question_data: Dict
    ) -> Optional[str]:
        """
        è§£æç”¨æˆ·é€‰æ‹©
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥ï¼ˆå¯èƒ½æ˜¯é€‰é¡¹å­—æ¯æˆ–é€‰é¡¹åç§°ï¼‰
            question_data: é—®é¢˜æ•°æ®
            
        Returns:
            é€‰ä¸­çš„é€‰é¡¹åç§°ï¼Œå¦‚æœæ— æ³•è§£æåˆ™è¿”å›None
        """
        user_input = user_input.strip().upper()
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯é€‰é¡¹å­—æ¯ï¼ˆA/B/C/D/Eï¼‰
        if len(user_input) == 1 and user_input in ['A', 'B', 'C', 'D', 'E']:
            # æ‰¾åˆ°å¯¹åº”çš„é€‰é¡¹
            for option in question_data['options']:
                if option['label'] == user_input:
                    return option['name']
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯é€‰é¡¹åç§°ï¼ˆå®Œå…¨åŒ¹é…æˆ–éƒ¨åˆ†åŒ¹é…ï¼‰
        user_input_lower = user_input.lower()
        for option in question_data['options']:
            option_name_lower = option['name'].lower()
            if user_input_lower == option_name_lower or user_input_lower in option_name_lower:
                return option['name']
        
        return None


# å…¨å±€é—®é¢˜ç”ŸæˆæœåŠ¡å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
_question_service_instance = None


def get_question_service() -> QuestionService:
    """è·å–é—®é¢˜ç”ŸæˆæœåŠ¡å®ä¾‹ï¼ˆå•ä¾‹ï¼‰"""
    global _question_service_instance
    if _question_service_instance is None:
        _question_service_instance = QuestionService()
    return _question_service_instance

